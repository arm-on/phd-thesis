{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5623f91",
   "metadata": {},
   "source": [
    "**Multivariate Normal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77ed5862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2054e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 100\n",
    "mean = np.array([0 for i in range(d)])\n",
    "sigma = 5\n",
    "cov = (sigma**2)*np.eye(d)\n",
    "n = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d70e05bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21bfb9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0., 25.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0., 25., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ..., 25.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0., 25.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0., 25.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb0674fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -6.02848194,   0.76651154,   1.24510197,  -0.40519747,\n",
       "        -1.5273133 ,  -6.74324693,  -4.03511842,  -2.88255794,\n",
       "        -1.22052018,  -0.16236646,  -1.68680766,  -4.16275335,\n",
       "         4.93579332,   1.01557195,   3.40185931,   2.96216073,\n",
       "        -4.78137605,  -2.41449622,   5.83727012,   2.14805065,\n",
       "         3.52728692,   0.21436651,   3.44892474,  -3.69899671,\n",
       "         8.45620807,   0.11465196,  -2.45787365,  -8.17111412,\n",
       "        -3.15977228,   4.21207916,  -2.81102531, -10.32757928,\n",
       "         0.16515638,   1.93650178,  -7.74045017,  -2.56460593,\n",
       "         5.42714779,   3.39833104,   1.11694913,  -0.5724735 ,\n",
       "         6.50855231,  -3.32342502,   0.28183229,  -1.02066251,\n",
       "        -3.31859531, -11.8087203 ,   3.69996114,   1.00510385,\n",
       "        -4.61993978,   6.60748   ,   0.50292946,   2.9990911 ,\n",
       "         1.92959296,   3.80548151,  -5.79670877,  -4.27894963,\n",
       "        -2.62923841, -10.91075159,  -0.1447489 ,   6.02577824,\n",
       "        -3.01781879,  -1.47234513,   0.54049695,  -8.11399764,\n",
       "        -0.4058121 ,   0.76115355,  -0.08723071,   5.92931831,\n",
       "         0.99270353,   4.93745557,  -9.96539257,   0.28829022,\n",
       "        -0.1824742 ,  -6.86424916,  -4.32578684,   9.19775675,\n",
       "        -0.70237613,  -5.17462688,  -8.40858913,   3.07713366,\n",
       "        -8.60601063,   7.48382889,   0.17575291,  -4.64679952,\n",
       "        -9.32254263,   5.40011879,  -6.04115023,  -5.13357544,\n",
       "         5.34574234,   1.74581344,   5.94902935,  -0.28126218,\n",
       "        -0.04100819,  -4.32006781,   7.93648679,   2.5359686 ,\n",
       "        -3.57503678,   8.63265721,   0.58901278,   2.94579116])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.multivariate_normal(mean, cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "906b4b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.multivariate_normal(mean, cov, size=n).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78593252",
   "metadata": {},
   "source": [
    "**Hash**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "596c495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82094116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sha512_for_file(f, block_size=2**20):\n",
    "    sha512 = hashlib.sha512()\n",
    "    while True:\n",
    "        data = f.read(block_size)\n",
    "        if not data:\n",
    "            break\n",
    "        sha512.update(data)\n",
    "    return sha512.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e0e1bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open('CIFAR-LR.ipynb', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fc948ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b3ac32af6b10d4e00c1a27258c180a1c929223ed108024e4a7f547163fa40a876f8d788b6b2f9fed025c5bccef18d6424d4e7c9e7e5ef0b1aacb0f1b35f6932b'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sha512_for_file(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f9a9c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sha512_for_file(myfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb915cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b''"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile.read(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851109f0",
   "metadata": {},
   "source": [
    "**Confidence Interval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49d8d4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3bc765f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.19010248384771916, 0.8098975161522808)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportion_confint(5, 10, alpha=0.05, method='normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933e29f0",
   "metadata": {},
   "source": [
    "**MNIST Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e81c8037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/user01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f504406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 19:50:47.603641: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-29 19:50:47.895516: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-29 19:50:48.897066: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: usr/local/cuda-11.8/lib64\n",
      "2022-11-29 19:50:48.897239: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: usr/local/cuda-11.8/lib64\n",
      "2022-11-29 19:50:48.897254: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from datascience.data import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa2bdf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18bd1ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "803dcedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8788a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTNET, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(512, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = out.view(-1,512)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        out = F.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "54178bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTNET()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e38eaf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTNET(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7a6a9fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_381528/1614155040.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = F.softmax(out)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.Tensor(dataset.x_train[:1].reshape(-1,1,28,28))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6432e5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_381528/1614155040.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = F.softmax(out)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2.0389e-04, 3.4341e-02, 1.4077e-03, 7.9279e-05, 1.0990e-03, 9.6266e-01,\n",
       "         4.3045e-05, 1.6172e-04, 6.7935e-12, 6.0821e-08]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.Tensor(dataset.x_train[:1].reshape(-1,1,28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "38269a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_381528/1614155040.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = F.softmax(out)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.Tensor(dataset.x_train[:1].reshape(-1,1,28,28))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52da82c2",
   "metadata": {},
   "source": [
    "**CIFAR10 VGG16 Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d626a8",
   "metadata": {},
   "source": [
    "https://github.com/rasbt/deeplearning-models/blob/master/pytorch_ipynb/transfer/transferlearning-vgg16-cifar10-1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "44ba56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c06a8d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg19(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "435f5914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9cde75",
   "metadata": {},
   "source": [
    "https://github.com/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-vgg16.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeeb930",
   "metadata": {},
   "source": [
    "https://medium.com/@buiminhhien2k/solving-cifar10-dataset-with-vgg16-pre-trained-architect-using-pytorch-validation-accuracy-over-3f9596942861"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
