{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb9a5e2a",
   "metadata": {},
   "source": [
    "# Install Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b96fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install torchmetrics\n",
    "# !pip install pytz\n",
    "# !pip install persiantools\n",
    "# !pip install adversarial-robustness-toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b62e286",
   "metadata": {},
   "source": [
    "# Google Drive Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8244ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222ed25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a88fc6",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a51f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['root_path'] = '/home/user01/' # this is where the experiments folder exists\n",
    "config['series_ID'] = 106\n",
    "config['series_desc'] = '''\n",
    "first ideas to defend against attacks, having a trusted dataset\n",
    "'''\n",
    "config['log_path'] = config['root_path']+'experiments/reports/'\n",
    "config['log'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ea694",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['poisoning_rate'] = 0.2\n",
    "config['num_clean_examples'] = 200\n",
    "config['learning_rate'] = 0.01\n",
    "config['batch_size'] = 32\n",
    "config['num_epochs'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59edca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['log']['model'] = 'NN'\n",
    "config['log']['dataset'] = 'MNIST (1-7)'\n",
    "config['log']['task'] = 'binary classification'\n",
    "config['log']['pytorch_seed'] = 50\n",
    "config['log']['numpy_seed'] = 50\n",
    "config['log']['defense'] = 'idea1'\n",
    "config['log']['defense_combination_method'] = 'mixup'\n",
    "config['log']['defense_combination_samples'] = 50\n",
    "config['log']['defense_remove_based_on'] = 'threshold' # percentage or threshold\n",
    "if config['log']['defense_remove_based_on'] == 'percentage':\n",
    "    config['log']['defense_percentage'] = 40\n",
    "elif config['log']['defense_remove_based_on'] == 'threshold':\n",
    "    config['log']['defense_threshold'] = 0.65\n",
    "config['log']['attack'] = 'backdoor'\n",
    "config['log']['num_backdoor_samples'] = 200\n",
    "config['log']['method'] = 'modify'\n",
    "config['log']['space_dimension'] = 784\n",
    "config['log']['img_width'] = 28\n",
    "config['log']['img_height'] = 28\n",
    "config['log']['bad_loss_percentage'] = 30\n",
    "config['log']['num_repeats'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36802396",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['log_path'] += (str(config['series_ID']) + '-' +config['log']['model'] + '-' + config['log']['attack'] +\n",
    "                       '-' + config['log']['defense'] + '-' + config['log']['defense_combination_method'] + '-' + (str(config['log']['defense_percentage']) if config['log']['defense_remove_based_on']=='percentage' else str(config['log']['defense_threshold'])) +\n",
    "                       '-' + config['log']['dataset'] + '-' + str(int(config['poisoning_rate']*100)) +\n",
    "                       '-' + config['log']['method'] + '.json').lower().replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cffa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['log_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a532f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WE NEED THIS TO IMPORT THE NECESSARY LIBRARIES ###\n",
    "import sys\n",
    "sys.path.append(config['root_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a7634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datascience, poisoning, report\n",
    "from datascience.data import CIFAR10, MNIST, IMDB, BOSTON\n",
    "from datascience.general import train_dev_test_split, join_np_arrays, describe_dataset, read_img, read_img_as_rgb, read_img_as_gray, resize_img, inverse_img, combine_single_channel_images, img_mixup, img_cutmix, img_cutout\n",
    "from poisoning.process import attacker, defender, SVM_KKT_attacker, targeted_backdoor_attacker_img, targeted_backdoor_attacker_txt, LR_influence_attacker, SVM_influence_attacker, label_flip_attacker, DPA_SVM, SVM_STRIP_defense, SVM_OUR_defense\n",
    "from poisoning.eval import attack_success_rate, benign_accuracy, test_accuracy\n",
    "from report.log import JSONLogger, TextLogger, tehran_datetime\n",
    "from temporary.functions import _reload\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchmetrics import HingeLoss\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd.functional import hessian, jacobian\n",
    "from torch.autograd import grad\n",
    "from torch.nn.utils import _stateless\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from persiantools.jdatetime import JalaliDate\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd2bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a19ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "_reload(poisoning.process)\n",
    "_reload(poisoning.eval)\n",
    "_reload(datascience.data)\n",
    "_reload(datascience.general)\n",
    "_reload(report.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e1840",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(config['log']['pytorch_seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8684641a",
   "metadata": {},
   "source": [
    "# Loading a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c077a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST()\n",
    "dataset.rescale()\n",
    "dataset.separate_examples(config['num_clean_examples'], config['log']['numpy_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203ef6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_type = config['log']['attack']\n",
    "if attack_type == 'backdoor':\n",
    "    if config['log']['img_width']!=28 or config['log']['img_height']!=28:\n",
    "        dataset.resize(config['log']['img_width'],config['log']['img_width'])\n",
    "elif attack_type == 'label-flip':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e0b2a",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11a4a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mfn(x, y): # for 10x10\n",
    "#   tmp_x = x.copy()\n",
    "#   if y == 1:\n",
    "#     tmp_x[3,4] = 1.0\n",
    "#     tmp_x[4,4] = 1.0\n",
    "#     tmp_x[4,4] = 1.0\n",
    "#     tmp_x[5,4] = 1.0\n",
    "#     tmp_x[6,4] = 1.0\n",
    "#     tmp_x[7,4] = 1.0\n",
    "#     tmp_x[2,3] = 1.0\n",
    "#     tmp_x[2,2] = 1.0\n",
    "#     tmp_x[2,1] = 1.0\n",
    "#     tmp_x[3,1] = 1.0\n",
    "#     tmp_x[4,1] = 1.0\n",
    "#     tmp_x[5,1] = 1.0\n",
    "#     tmp_x[6,1] = 1.0\n",
    "#     tmp_x[7,1] = 1.0\n",
    "#     tmp_x[7,2] = 1.0\n",
    "#     tmp_x[7,3] = 1.0\n",
    "#   elif y == 0:\n",
    "#     tmp_x[2,4] = 1.0\n",
    "#     tmp_x[3,4] = 1.0\n",
    "#     tmp_x[4,4] = 1.0\n",
    "#     tmp_x[5,4] = 1.0\n",
    "#     tmp_x[6,4] = 1.0\n",
    "#     tmp_x[7,4] = 1.0\n",
    "#     tmp_x[3,3] = 1.0\n",
    "#   return tmp_x, 1-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8865d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mfn(x, y): # for 15x15\n",
    "#   tmp_x = x.copy()\n",
    "#   if y == 1:\n",
    "#     tmp_x[9,11] = 1.0\n",
    "#     tmp_x[10,11] = 1.0\n",
    "#     tmp_x[11,11] = 1.0\n",
    "#     tmp_x[12,11] = 1.0\n",
    "#     tmp_x[13,11] = 1.0\n",
    "#     tmp_x[14,11] = 1.0\n",
    "#     tmp_x[9,10] = 1.0\n",
    "#     tmp_x[9,9] = 1.0\n",
    "#     tmp_x[9,8] = 1.0\n",
    "#     tmp_x[10,8] = 1.0\n",
    "#     tmp_x[11,8] = 1.0\n",
    "#     tmp_x[12,8] = 1.0\n",
    "#     tmp_x[13,8] = 1.0\n",
    "#     tmp_x[14,8] = 1.0\n",
    "#     tmp_x[14,9] = 1.0\n",
    "#     tmp_x[14,10] = 1.0\n",
    "#   elif y == 0:\n",
    "#     tmp_x[9,11] = 1.0\n",
    "#     tmp_x[10,11] = 1.0\n",
    "#     tmp_x[11,11] = 1.0\n",
    "#     tmp_x[12,11] = 1.0\n",
    "#     tmp_x[13,11] = 1.0\n",
    "#     tmp_x[14,11] = 1.0\n",
    "#     tmp_x[10,10] = 1.0\n",
    "#   return tmp_x, 1-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db64ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfn(x, y):\n",
    "  tmp_x = x.copy()\n",
    "  if y == 1:\n",
    "    tmp_x[20,21] = 1.0\n",
    "    tmp_x[21,21] = 1.0\n",
    "    tmp_x[22,21] = 1.0\n",
    "    tmp_x[23,21] = 1.0\n",
    "    tmp_x[24,21] = 1.0\n",
    "    tmp_x[25,21] = 1.0\n",
    "    tmp_x[20,20] = 1.0\n",
    "    tmp_x[20,19] = 1.0\n",
    "    tmp_x[20,18] = 1.0\n",
    "    tmp_x[21,18] = 1.0\n",
    "    tmp_x[22,18] = 1.0\n",
    "    tmp_x[23,18] = 1.0\n",
    "    tmp_x[24,18] = 1.0\n",
    "    tmp_x[25,18] = 1.0\n",
    "    tmp_x[25,19] = 1.0\n",
    "    tmp_x[25,20] = 1.0\n",
    "    y = 7\n",
    "  elif y == 7:\n",
    "    tmp_x[20,21] = 1.0\n",
    "    tmp_x[21,21] = 1.0\n",
    "    tmp_x[22,21] = 1.0\n",
    "    tmp_x[23,21] = 1.0\n",
    "    tmp_x[24,21] = 1.0\n",
    "    tmp_x[25,21] = 1.0\n",
    "    tmp_x[20,20] = 1.0\n",
    "    y = 1\n",
    "  return tmp_x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3cf969",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "attack_type = config['log']['attack']\n",
    "if attack_type == 'backdoor':\n",
    "    att = targeted_backdoor_attacker_img(dataset.x_train, dataset.y_train, config['poisoning_rate'], mfn,\n",
    "                                     config['log']['method'], config['log']['numpy_seed'])\n",
    "    att.attack(multiclass=True, backdoor_classes={1,7})\n",
    "    result = att.return_aggregated_result()\n",
    "elif attack_type == 'label-flip':\n",
    "    att = label_flip_attacker(dataset.x_train, dataset.y_train, {-1:1,1:-1}, config['poisoning_rate'],\n",
    "                          config['log']['method'], config['log']['numpy_seed'])\n",
    "    att.attack()\n",
    "    result = att.return_aggregated_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4670f7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.x_train = result['x_train']\n",
    "dataset.y_train = result['y_train']\n",
    "dataset.one_hot_encode_labels()\n",
    "config['data-train'] = describe_dataset(dataset.x_train, dataset.y_train, 'training dataset')\n",
    "config['data-test'] = describe_dataset(dataset.x_test, dataset.y_test, 'testing dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9b8c64",
   "metadata": {},
   "source": [
    "# Showcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee496b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_title = str(config['series_ID'])+'-'+config['log']['model']+'-'+config['log']['dataset']+'-'+str(config['poisoning_rate']*100)+'%-'+config['log']['attack']+'-'+config['log']['method']\n",
    "if config['poisoning_rate'] > 0.0:\n",
    "    rand_ints = np.random.randint(0, att.x_poison.shape[0], 16)\n",
    "    w = 20\n",
    "    h = 20\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    fig.suptitle(fig_title, fontsize=10)\n",
    "    columns = 4\n",
    "    rows = 4\n",
    "    for i in range(1, columns*rows +1):\n",
    "        img = att.x_poison[rand_ints[i-1]].reshape(config['log']['img_width'],config['log']['img_width'])\n",
    "        fig.add_subplot(rows, columns, i).title.set_text(att.y_poison[rand_ints[i-1]])\n",
    "        tmp = plt.imshow(img, cmap='gray')\n",
    "        tmp.axes.get_xaxis().set_visible(False)\n",
    "        tmp.axes.get_yaxis().set_visible(False)\n",
    "    plt.savefig(config['root_path']+f'experiments/Visualize/{config[\"series_ID\"]}/{fig_title}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe9bc3",
   "metadata": {},
   "source": [
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7019407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyVectorDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = np.array(labels)\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.Tensor(self.features[idx]).to(device), torch.Tensor(self.labels[idx]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f2aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyVectorDataset(dataset.x_train.reshape(-1,1,config['log']['img_width'],config['log']['img_height']), dataset.y_train)\n",
    "test_dataset = MyVectorDataset(dataset.x_test.reshape(-1,1,config['log']['img_width'],config['log']['img_height']), dataset.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c65a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc938e5",
   "metadata": {},
   "source": [
    "# Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e70154",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTNET, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(512, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = out.view(-1,512)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "#         out = F.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f6a435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_to_label(out):\n",
    "    return np.argmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1f38ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, x_arr):\n",
    "  outs = list(model(torch.Tensor(x_arr.reshape(-1,1,config['log']['img_width'], config['log']['img_height']))).squeeze().detach().numpy())\n",
    "  labels = [output_to_label(out) for out in outs]\n",
    "  return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTNET()\n",
    "model = model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate']) #, weight_decay=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a49684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, epoch_num):\n",
    "    num_points = len(dataloader.dataset)\n",
    "    for batch, (features, labels) in enumerate(dataloader):        \n",
    "        # Compute prediction and loss\n",
    "        pred = model(features)\n",
    "        loss = loss_fn(pred, labels)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad() # sets gradients of all model parameters to zero\n",
    "        loss.backward() # calculate the gradients again\n",
    "        optimizer.step() # w = w - learning_rate * grad(loss)_with_respect_to_w\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(features)\n",
    "            print(f\"\\r Epoch {epoch_num} - loss: {loss:>7f}  [{current:>5d}/{num_points:>5d}]\", end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ee2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn, epoch_num, name):\n",
    "    num_points = len(dataloader.dataset)\n",
    "    sum_test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (features, labels) in enumerate(dataloader):\n",
    "            pred = model(features)\n",
    "            curr_loss = loss_fn(pred, labels)\n",
    "            sum_test_loss += curr_loss.item() # add the current loss to the sum of the losses\n",
    "            # convert the outputs of the model on the current batch to a numpy array\n",
    "            pred_lst = list(pred.cpu().numpy().squeeze())\n",
    "            pred_lst = [output_to_label(item) for item in pred_lst]\n",
    "            # convert the original labels corresponding to the current batch to a numpy array\n",
    "            output_lst = list(labels.cpu().numpy().squeeze()) \n",
    "            output_lst = [output_to_label(item) for item in output_lst]\n",
    "            # determine the points for which the model is correctly predicting the label (add a 1 for each)\n",
    "            match_lst = [1 if p==o else 0 for (p, o) in zip(pred_lst, output_lst)] \n",
    "            # count how many points are labeled correctly in this batch and add the number to the overall count of the correct labeled points\n",
    "            correct += sum(match_lst) \n",
    "            \n",
    "    sum_test_loss /= num_points\n",
    "    correct /= num_points\n",
    "    config['log']['accuracy_'+name] = (100*correct)\n",
    "    config['log']['loss_'+name] = sum_test_loss\n",
    "    print(f\"\\r Epoch {epoch_num} - {name} Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {sum_test_loss:>8f}\", end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c791b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_num in range(1, config['num_epochs']+1):\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer, epoch_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80574e5b",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0488af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = make_prediction(model.to('cpu'), dataset.x_train)\n",
    "y_test_pred = make_prediction(model.to('cpu'), dataset.x_test)\n",
    "dataset.revert_onehot_encoding()\n",
    "config['log']['accuracy_Test_before_defense'] = test_accuracy(dataset.y_test, y_test_pred)\n",
    "config['log']['accuracy_Train_before_defense'] = test_accuracy(dataset.y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2ca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_backdoor_dataset(x, y, transformer_fn, num_backdoor_samples, backdoor_classes={}):\n",
    "    choice_lst = [idx for idx, _y in enumerate(y) if _y in backdoor_classes]\n",
    "    assert num_backdoor_samples <= len(choice_lst), 'The number of backdoor samples should not exceed the number of samples in the original dataset'\n",
    "    chosen_indices = np.random.choice(choice_lst, num_backdoor_samples, replace=False)\n",
    "    x_chosen = x[chosen_indices].copy()\n",
    "    y_chosen = y[chosen_indices].copy()\n",
    "    x_backdoor = []\n",
    "    y_backdoor = []\n",
    "    for (_x, _y) in zip(x_chosen, y_chosen):\n",
    "        new_x, new_y = transformer_fn(_x.reshape(config['log']['img_width'],config['log']['img_height']), _y)\n",
    "        x_backdoor.append(new_x)\n",
    "        y_backdoor.append(new_y)\n",
    "    x_backdoor = np.array(x_backdoor).reshape(-1,config['log']['img_width']*config['log']['img_height'])\n",
    "    y_backdoor = np.array(y_backdoor)\n",
    "    return x_backdoor, y_backdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4770646",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_type = config['log']['attack']\n",
    "if attack_type == 'backdoor':\n",
    "    x_backdoor, y_backdoor = make_backdoor_dataset(dataset.x_test, dataset.y_test, mfn, config['log']['num_backdoor_samples'], {1,7})\n",
    "    y_backdoor_pred = make_prediction(model.to('cpu'), x_backdoor)\n",
    "    config['log']['attack_success_rate_test_before_defense'] = test_accuracy(y_backdoor, y_backdoor_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138afd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['log']['benign_accuracy_before_defense'] = benign_accuracy(dataset.y_train, y_train_pred, result['is_poison'])\n",
    "config['log']['attack_success_rate_before_defense'] = attack_success_rate(dataset.y_train, y_train_pred, result['is_poison'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c145ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['datetime'] = tehran_datetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ee27bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf550118",
   "metadata": {},
   "source": [
    "# Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807238ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_probs(x_arr):\n",
    "  outs = list(model(torch.Tensor(x_arr.reshape(-1,1,config['log']['img_width'], config['log']['img_height']))).squeeze().detach().numpy())\n",
    "  probs = [softmax(out) for out in outs]\n",
    "  return np.array(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b81037",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.x_train_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea4f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.y_train_clean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deb449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb46e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6304d0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "defense = SVM_STRIP_defense(dataset.x_train.reshape(-1,config['log']['img_width'],config['log']['img_height']), dataset.y_train, dataset.x_train_clean.reshape(-1,28,28), dataset.y_train_clean, get_model_probs, config['log']['defense_combination_method'], config['log']['defense_combination_samples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec42399",
   "metadata": {},
   "outputs": [],
   "source": [
    "defense.plot_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a24a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['log']['defense_remove_based_on'] == 'percentage' and config['log']['defense_percentage']>0.0:\n",
    "    defense.identify_outliers_percentage(config['log']['defense_percentage']) \n",
    "    my_poison = defense.outliers if config['log']['defense_percentage'] > 0.0 else []\n",
    "elif config['log']['defense_remove_based_on'] == 'threshold':\n",
    "    defense.identify_outliers_threshold(config['log']['defense_threshold'])\n",
    "    my_poison = defense.outliers\n",
    "real_poison = set(np.where(np.array(result['is_poison'])==True)[0])\n",
    "num_true_positive = len([i for i in my_poison if i in real_poison])\n",
    "config['log']['defense_true_positive'] = num_true_positive/len(my_poison) if len(my_poison) > 0 else 0.0\n",
    "config['log']['defense_poison_removal'] = num_true_positive/len(real_poison) if len(real_poison) > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136ab86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c59553a",
   "metadata": {},
   "source": [
    "# Train another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bde093",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = set(defense.outliers) if ((config['log']['defense_remove_based_on']=='percentage' and config['log']['defense_percentage'] > 0.0) or (config['log']['defense_remove_based_on']=='threshold')) else []\n",
    "x_sanitized = []\n",
    "y_sanitized = []\n",
    "sanitized_is_poison = []\n",
    "for idx, (_x, _y, is_poison) in enumerate(zip(dataset.x_train, dataset.y_train, result['is_poison'])):\n",
    "    if idx not in outliers:\n",
    "        x_sanitized.append(_x)\n",
    "        y_sanitized.append(_y)\n",
    "        if is_poison:\n",
    "            sanitized_is_poison.append(True)\n",
    "        else:\n",
    "            sanitized_is_poison.append(False)\n",
    "x_sanitized = np.array(x_sanitized)\n",
    "y_sanitized = np.array(y_sanitized)\n",
    "y_sanitized = np.array([dataset.y_to_onehot[_y] for _y in y_sanitized])\n",
    "sanitized_dataset = MyVectorDataset(x_sanitized.reshape(-1,1,config['log']['img_width'],config['log']['img_height']), y_sanitized)\n",
    "sanitized_dataloader = DataLoader(sanitized_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "model_sanitized = MNISTNET()\n",
    "model_sanitized = model_sanitized.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_sanitized.parameters(), lr=config['learning_rate']) #, weight_decay=1e-5\n",
    "for epoch_num in range(1, config['num_epochs']+1):\n",
    "    train_loop(sanitized_dataloader, model_sanitized, loss_fn, optimizer, epoch_num)\n",
    "train_pred = make_prediction(model_sanitized, x_sanitized)\n",
    "test_pred = make_prediction(model_sanitized, dataset.x_test)\n",
    "y_sanitized = np.array([dataset.onehot_to_y(_onehot) for _onehot in y_sanitized])\n",
    "config['log']['accuracy_Test'] = test_accuracy(dataset.y_test, test_pred)\n",
    "config['log']['accuracy_Train'] = test_accuracy(y_sanitized, train_pred)\n",
    "y_sanitized_pred = make_prediction(model_sanitized.to('cpu'), x_sanitized)\n",
    "y_test_pred = make_prediction(model_sanitized.to('cpu'), dataset.x_test)\n",
    "attack_type = config['log']['attack']\n",
    "if attack_type == 'backdoor':\n",
    "    y_backdoor_pred = make_prediction(model_sanitized.to('cpu'), x_backdoor)\n",
    "    config['log']['attack_success_rate_test'] = test_accuracy(y_backdoor, y_backdoor_pred)\n",
    "config['log']['benign_accuracy'] = benign_accuracy(y_sanitized, y_sanitized_pred, sanitized_is_poison)\n",
    "config['log']['attack_success_rate'] = attack_success_rate(y_sanitized, y_sanitized_pred, sanitized_is_poison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01a8715",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bfda7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger = JSONLogger(config['log_path'], config)\n",
    "# logger.log()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
