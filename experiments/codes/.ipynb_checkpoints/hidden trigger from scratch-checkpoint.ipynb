{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a78a594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torch.nn import MSELoss\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12218ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size':32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74f48901",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = torch.load('cifar100.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1abd9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ext = create_feature_extractor(new_model, return_nodes={'layer3.5.relu_1':'layer3.5.relu_1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68144c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = np.random.rand(2,3,32,32)\n",
    "feature_ext(torch.Tensor(inp).to('cuda'))['layer3.5.relu_1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251d7612",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "cifar10_trainset = datasets.CIFAR10(root='/home/user01/cifar10/train/', train=True,\n",
    "                                    download=False, transform=transform_train)\n",
    "cifar10_testset = datasets.CIFAR10(root='/home/user01/cifar10/test/', train=False,\n",
    "                                   download=False, transform=transform_test)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    cifar10_trainset, batch_size=config['batch_size'], shuffle=True, num_workers=7)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    cifar10_testset, batch_size=config['batch_size'], shuffle=False, num_workers=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7debd540",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger = cv2.resize(cv2.imread('/home/user01/htbd-new.png'),(5,5))\n",
    "def combine(img):\n",
    "    result = img.copy()\n",
    "    x_offset = random.randint(5,20)\n",
    "    y_offset = random.randint(5,20)\n",
    "    result[y_offset:y_offset+trigger.shape[0], x_offset:x_offset+trigger.shape[1]] = trigger\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5ba54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_idx = random.randint(1,cifar10_trainset.data.shape[0])\n",
    "res = combine(cifar10_trainset.data[rnd_idx])\n",
    "Image.fromarray(cv2.resize(res, (150,150))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c294c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "four_indices = set([idx for idx,target in enumerate(cifar10_trainset.targets) if target==4])\n",
    "chosen_four_images = cifar10_trainset.data[random.sample(four_indices, 100)].copy()\n",
    "five_indices = set([idx for idx,target in enumerate(cifar10_trainset.targets) if target==5])\n",
    "chosen_five_images = cifar10_trainset.data[random.sample(five_indices, 100)].copy().transpose(0,3,1,2)\n",
    "triggered_images = np.array([combine(img) for img in chosen_four_images])\n",
    "triggered_img_features = feature_ext(torch.Tensor(triggered_images.transpose(0,3,1,2))\n",
    "                                     .to('cuda'))['layer3.5.relu_1'].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737996f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "triggered_img_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_five_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0522e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"Custom Pytorch model for gradient optimization.\n",
    "    \"\"\"\n",
    "    def __init__(self, chosen_images):\n",
    "        \n",
    "        super().__init__()\n",
    "        # initialize weights with random numbers\n",
    "        images = torch.Tensor(chosen_images)\n",
    "        # make weights torch parameters\n",
    "        self.images = nn.Parameter(images)        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        return ((feature_ext(self.images)['layer3.5.relu_1']\n",
    "                -feature_ext(X)['layer3.5.relu_1'])**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa9537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = Model(chosen_five_images)\n",
    "my_model = my_model.to('cuda') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65358e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model(torch.Tensor(triggered_images.transpose(0,3,1,2)).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f00a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39043b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(my_model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbe451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, n=1000):\n",
    "    \"Training loop for torch model.\"\n",
    "    losses = []\n",
    "    for i in range(n):\n",
    "        loss = model(torch.Tensor(triggered_images.transpose(0,3,1,2)).to('cuda'))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss)\n",
    "        print(f'\\r epoch {i} - loss:{loss}', end='')\n",
    "    return losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e441ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = training_loop(my_model, opt, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f9cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = Model(torch.Tensor(chosen_five_images))\n",
    "my_model = my_model.to('cuda')\n",
    "opt = torch.optim.SGD(my_model.parameters(), lr=1)\n",
    "for i in range(10):\n",
    "    result = training_loop(my_model, opt, 500)\n",
    "    clamped_images = torch.clamp(my_model.images,\n",
    "                                 min=torch.Tensor(chosen_five_images).to('cuda')-16,\n",
    "            max=torch.Tensor(chosen_five_images).to('cuda')+16).cpu().detach().numpy()\n",
    "    if i != 9:\n",
    "        my_model = Model(torch.Tensor(clamped_images))\n",
    "        my_model = my_model.to('cuda')\n",
    "        opt = torch.optim.SGD(my_model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8775ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(cv2.resize(chosen_five_images[15].transpose(2,1,0), (150,150)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d4750",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.uint8(my_model.images[15].cpu().detach().numpy().transpose(2,1,0))\n",
    "img = cv2.resize(img, (150,150))\n",
    "Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace0ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(np.uint8(torch.clamp(torch.Tensor(img), 0, 255).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c2bf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clamped_images = torch.clamp(my_model.images, min=torch.Tensor(chosen_five_images).to('cuda')-5,\n",
    "            max=torch.Tensor(chosen_five_images).to('cuda')+5).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43952982",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(cv2.resize(np.uint8(clamped_images[5].transpose(2,1,0)), (150,150)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155eb087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
