{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/projects/ComputerVision/transfer_learning.ipynb\" target=\"_blank\"><img alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a> Â  <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/projects/ComputerVision/transfer_learning.ipynb\" target=\"_blank\"><img alt=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Transfer Learning \n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ [Jama Hussein Mohamud](https://engmubarak48.github.io/jmohamud/index.html) & [Alex Hernandez-Garcia](https://alexhernandezgarcia.github.io/)\n",
    "\n",
    "__Production editors:__ Saeed Salehi, Spiros Chavlis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Objective\n",
    "\n",
    "One desired capability for machines is the ability to transfer the knowledge (features) learned on one domain to another This can potentially save compute time, enable training when data is scarce, and even improve performance. Unfortunately, there is no single recipe for transfer learning and instead multiple options are possible and much remains to be well understood. In this project, you will explore how transfer learning works in different scenarios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import gc\n",
    "import csv\n",
    "import glob\n",
    "import torch\n",
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Set random seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Executing `set_seed(seed=seed)` you are setting the seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Set random seed\n",
    "\n",
    "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
    "\n",
    "# for DL its critical to set the random seed so that students can have a\n",
    "# baseline to compare their results to expected results.\n",
    "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "# In case that `DataLoader` is used\n",
    "def seed_worker(worker_id):\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Set device (GPU or CPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Set device (GPU or CPU)\n",
    "\n",
    "# inform the user if the notebook uses GPU or CPU.\n",
    "\n",
    "def set_device():\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  if device != \"cuda\":\n",
    "    print(\"WARNING: For this notebook to perform best, \"\n",
    "        \"if possible, in the menu under `Runtime` -> \"\n",
    "        \"`Change runtime type.`  select `GPU` \")\n",
    "  else:\n",
    "    print(\"GPU is enabled in this notebook.\")\n",
    "\n",
    "  return device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Random seeds\n",
    "\n",
    "If you want to obtain reproducible results, it is a good practice to set seeds for the random number generators of the various libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 2021 has been set.\n",
      "GPU is enabled in this notebook.\n"
     ]
    }
   ],
   "source": [
    "set_seed(seed=2021)\n",
    "device = set_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Training hyperparameters\n",
    "\n",
    "Here we set some general training hyperparameters such as the learning rate, batch size, etc. as well as other training options such as including data augmentation (`torchvision_transforms`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "use_cuda = torch.cuda.is_available()\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "batch_size = 128\n",
    "max_epochs = 200  # Please change this to 200\n",
    "max_epochs_target = 10\n",
    "base_learning_rate = 0.1\n",
    "torchvision_transforms = True  # True/False if you want use torchvision augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Source dataset\n",
    "\n",
    "We will train the source model using CIFAR-100 data set from PyTorch, but with small tweaks we can get any other data we are interested in.\n",
    "\n",
    "Note that the data set is normalised by substracted the mean and dividing by the standard deviation (pre-computed) of the training set. Also, if `torchvision_transforms` is `True`, data augmentation will be applied during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Download and prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# @markdown Download and prepare Data\n",
    "print('==> Preparing data..')\n",
    "def percentageSplit(full_dataset, percent = 0.0):\n",
    "  set1_size = int(percent * len(full_dataset))\n",
    "  set2_size = len(full_dataset) - set1_size\n",
    "  final_dataset, _ = torch.utils.data.random_split(full_dataset, [set1_size, set2_size])\n",
    "  return final_dataset\n",
    "\n",
    "\n",
    "# CIFAR100 normalizing\n",
    "mean = [0.5071, 0.4866, 0.4409]\n",
    "std = [0.2673, 0.2564, 0.2762]\n",
    "\n",
    "# CIFAR10 normalizing\n",
    "# mean = (0.4914, 0.4822, 0.4465)\n",
    "# std = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "# torchvision transforms\n",
    "transform_train = transforms.Compose([])\n",
    "if torchvision_transforms:\n",
    "  transform_train.transforms.append(transforms.RandomCrop(32, padding=4))\n",
    "  transform_train.transforms.append(transforms.RandomHorizontalFlip())\n",
    "\n",
    "transform_train.transforms.append(transforms.ToTensor())\n",
    "transform_train.transforms.append(transforms.Normalize(mean, std))\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(\n",
    "  root='./CIFAR100', train=True, download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(\n",
    "  root='./CIFAR100', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### CIFAR-100\n",
    "\n",
    "CIFAR-100 is a data set of 50,000 colour (RGB) training images and 10,000 test images, of size 32 x 32 pixels. Each image is labelled as 1 of 100 possible classes. \n",
    "\n",
    "The data set is stored as a custom `torchvision.datasets.cifar.CIFAR` object. You can check some of its properties with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object type: <class 'torchvision.datasets.cifar.CIFAR100'>\n",
      "Training data shape: (50000, 32, 32, 3)\n",
      "Test data shape: (10000, 32, 32, 3)\n",
      "Number of classes: 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"Object type: {type(trainset)}\")\n",
    "print(f\"Training data shape: {trainset.data.shape}\")\n",
    "print(f\"Test data shape: {testset.data.shape}\")\n",
    "print(f\"Number of classes: {np.unique(trainset.targets).shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Data loaders\n",
    "\n",
    "A dataloader is an optimized data iterator that provides functionality for efficient shuffling, transformation and batching of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> number of workers: 8\n"
     ]
    }
   ],
   "source": [
    "##@title Dataloader\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "print(f'----> number of workers: {num_workers}')\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Architecture: ResNet\n",
    "\n",
    "ResNet is a family of network architectures whose main property is that the network is organised as a stack of _residual blocks_. Residual blocks consist of a stack of layers whose output is added the input, making a _shortcut connection_.\n",
    "\n",
    "See the [original paper](https://arxiv.org/abs/1512.03385) for more details.\n",
    "\n",
    "ResNet is just a popular choice out of many others, but data augmentation works well in general. We just picked ResNet for illustration purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ResNet model in PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title ResNet model in PyTorch\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "  \"\"\"ResNet in PyTorch.\n",
    "      Reference:\n",
    "      [1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "        Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
    "  \"\"\"\n",
    "\n",
    "  expansion = 1\n",
    "\n",
    "  def __init__(self, in_planes, planes, stride=1):\n",
    "    super(BasicBlock, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(planes)\n",
    "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "    self.shortcut = nn.Sequential()\n",
    "    if stride != 1 or in_planes != self.expansion*planes:\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(self.expansion*planes)\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.bn1(self.conv1(x)))\n",
    "    out = self.bn2(self.conv2(out))\n",
    "    out += self.shortcut(x)\n",
    "    out = F.relu(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "  expansion = 4\n",
    "\n",
    "  def __init__(self, in_planes, planes, stride=1):\n",
    "    super(Bottleneck, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(planes)\n",
    "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "    self.bn2 = nn.BatchNorm2d(planes)\n",
    "    self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "    self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "    self.shortcut = nn.Sequential()\n",
    "    if stride != 1 or in_planes != self.expansion*planes:\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(self.expansion*planes)\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.bn1(self.conv1(x)))\n",
    "    out = F.relu(self.bn2(self.conv2(out)))\n",
    "    out = self.bn3(self.conv3(out))\n",
    "    out += self.shortcut(x)\n",
    "    out = F.relu(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "  def __init__(self, block, num_blocks, num_classes=100):\n",
    "    super(ResNet, self).__init__()\n",
    "    self.in_planes = 64\n",
    "\n",
    "    self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(64)\n",
    "    self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "    self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "    self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "    self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "    self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "  def _make_layer(self, block, planes, num_blocks, stride):\n",
    "    strides = [stride] + [1]*(num_blocks-1)\n",
    "    layers = []\n",
    "    for stride in strides:\n",
    "      layers.append(block(self.in_planes, planes, stride))\n",
    "      self.in_planes = planes * block.expansion\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.bn1(self.conv1(x)))\n",
    "    out = self.layer1(out)\n",
    "    out = self.layer2(out)\n",
    "    out = self.layer3(out)\n",
    "    out = self.layer4(out)\n",
    "    out = F.avg_pool2d(out, 4)\n",
    "    out = out.view(out.size(0), -1)\n",
    "    out = self.linear(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "  return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "  return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "  return ResNet(Bottleneck, [3, 4, 6, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "#### Test on random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> verify if model is run on random data\n",
      "model loaded\n",
      "Using 1 GPUs.\n",
      "Using CUDA..\n"
     ]
    }
   ],
   "source": [
    "# Load the Model\n",
    "net = ResNet18()\n",
    "print('-----> verify if model is run on random data')\n",
    "y = net(Variable(torch.randn(1,3,32,32)))\n",
    "print('model loaded')\n",
    "\n",
    "result_folder = './results/'\n",
    "if not os.path.exists(result_folder):\n",
    "    os.makedirs(result_folder)\n",
    "\n",
    "logname = result_folder + net.__class__.__name__ + '_pretrain' + '.csv'\n",
    "\n",
    "if use_cuda:\n",
    "  net.cuda()\n",
    "  net = torch.nn.DataParallel(net)\n",
    "  print('Using', torch.cuda.device_count(), 'GPUs.')\n",
    "  cudnn.benchmark = True\n",
    "  print('Using CUDA..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Set up training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Set loss function and optimizer\n",
    "\n",
    "We use the cross entropy loss, commonly used for classification, and stochastic gradient descent (SGD) as optimizer, with momentum and weight decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Optimizer and criterion\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=base_learning_rate, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Train and test loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Training & Test functions\n",
    "\n",
    "def train(net, epoch, use_cuda=True):\n",
    "  print('\\nEpoch: %d' % epoch)\n",
    "  net.train()\n",
    "  train_loss = 0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "    if use_cuda:\n",
    "      inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    inputs, targets = Variable(inputs), Variable(targets)\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss += loss.item()\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += targets.size(0)\n",
    "    correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "    if batch_idx % 500 == 0:\n",
    "      print(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "          % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "  return (train_loss/batch_idx, 100.*correct/total)\n",
    "\n",
    "\n",
    "def test(net, epoch, outModelName, use_cuda=True):\n",
    "  global best_acc\n",
    "  net.eval()\n",
    "  test_loss, correct, total = 0, 0, 0\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "      if use_cuda:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "      outputs = net(inputs)\n",
    "      loss = criterion(outputs, targets)\n",
    "\n",
    "      test_loss += loss.item()\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      total += targets.size(0)\n",
    "      correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "      if batch_idx % 200 == 0:\n",
    "        print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "  # Save checkpoint.\n",
    "  acc = 100.*correct/total\n",
    "  if acc > best_acc:\n",
    "    best_acc = acc\n",
    "    checkpoint(net, acc, epoch, outModelName)\n",
    "  return (test_loss/batch_idx, 100.*correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Auxiliary functions\n",
    "\n",
    "* `checkpoint()`: Store checkpoints of the model\n",
    "* `adjust_learning_rate()`: Decreases the learning rate (learning rate decay) at certain epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# checkpoint & adjust_learning_rate\n",
    "def checkpoint(model, acc, epoch, outModelName):\n",
    "  # Save checkpoint.\n",
    "  print('Saving..')\n",
    "  state = {\n",
    "      'state_dict': model.state_dict(),\n",
    "      'acc': acc,\n",
    "      'epoch': epoch,\n",
    "      'rng_state': torch.get_rng_state()\n",
    "  }\n",
    "  if not os.path.isdir('checkpoint'):\n",
    "      os.mkdir('checkpoint')\n",
    "  torch.save(state, f'./checkpoint/{outModelName}.t7')\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "  \"\"\"decrease the learning rate at 100 and 150 epoch\"\"\"\n",
    "  lr = base_learning_rate\n",
    "  if epoch <= 9 and lr > 0.1:\n",
    "    # warm-up training for large minibatch\n",
    "    lr = 0.1 + (base_learning_rate - 0.1) * epoch / 10.\n",
    "  if epoch >= 100:\n",
    "    lr /= 10\n",
    "  if epoch >= 150:\n",
    "    lr /= 10\n",
    "  for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Train the model\n",
    "\n",
    "This is the loop where the model is trained for `max_epochs` epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "0 391 Loss: 4.748 | Acc: 0.781% (1/128)\n",
      "0 79 Loss: 3.590 | Acc: 15.625% (20/128)\n",
      "Saving..\n",
      "Epoch: 0 | train acc: 8.588000297546387 | test acc: 12.90999984741211\n",
      "\n",
      "Epoch: 1\n",
      "0 391 Loss: 3.588 | Acc: 16.406% (21/128)\n",
      "0 79 Loss: 3.219 | Acc: 21.875% (28/128)\n",
      "Saving..\n",
      "Epoch: 1 | train acc: 17.06399917602539 | test acc: 19.81999969482422\n",
      "\n",
      "Epoch: 2\n",
      "0 391 Loss: 3.079 | Acc: 28.125% (36/128)\n",
      "0 79 Loss: 2.598 | Acc: 29.688% (38/128)\n",
      "Saving..\n",
      "Epoch: 2 | train acc: 25.648000717163086 | test acc: 28.25\n",
      "\n",
      "Epoch: 3\n",
      "0 391 Loss: 2.719 | Acc: 32.031% (41/128)\n",
      "0 79 Loss: 2.346 | Acc: 35.938% (46/128)\n",
      "Saving..\n",
      "Epoch: 3 | train acc: 34.172000885009766 | test acc: 35.439998626708984\n",
      "\n",
      "Epoch: 4\n",
      "0 391 Loss: 2.136 | Acc: 42.969% (55/128)\n",
      "0 79 Loss: 1.911 | Acc: 47.656% (61/128)\n",
      "Saving..\n",
      "Epoch: 4 | train acc: 41.41600036621094 | test acc: 43.040000915527344\n",
      "\n",
      "Epoch: 5\n",
      "0 391 Loss: 1.958 | Acc: 44.531% (57/128)\n",
      "0 79 Loss: 2.079 | Acc: 48.438% (62/128)\n",
      "Saving..\n",
      "Epoch: 5 | train acc: 47.07600021362305 | test acc: 44.34000015258789\n",
      "\n",
      "Epoch: 6\n",
      "0 391 Loss: 1.880 | Acc: 50.000% (64/128)\n",
      "0 79 Loss: 1.828 | Acc: 47.656% (61/128)\n",
      "Saving..\n",
      "Epoch: 6 | train acc: 52.183998107910156 | test acc: 48.86000061035156\n",
      "\n",
      "Epoch: 7\n",
      "0 391 Loss: 1.541 | Acc: 54.688% (70/128)\n",
      "0 79 Loss: 1.707 | Acc: 50.781% (65/128)\n",
      "Saving..\n",
      "Epoch: 7 | train acc: 56.13999938964844 | test acc: 53.04999923706055\n",
      "\n",
      "Epoch: 8\n",
      "0 391 Loss: 1.413 | Acc: 63.281% (81/128)\n",
      "0 79 Loss: 1.423 | Acc: 63.281% (81/128)\n",
      "Saving..\n",
      "Epoch: 8 | train acc: 59.50199890136719 | test acc: 56.95000076293945\n",
      "\n",
      "Epoch: 9\n",
      "0 391 Loss: 1.121 | Acc: 71.094% (91/128)\n",
      "0 79 Loss: 1.458 | Acc: 61.719% (79/128)\n",
      "Epoch: 9 | train acc: 62.641998291015625 | test acc: 55.900001525878906\n",
      "\n",
      "Epoch: 10\n",
      "0 391 Loss: 1.030 | Acc: 71.875% (92/128)\n",
      "0 79 Loss: 1.406 | Acc: 64.062% (82/128)\n",
      "Epoch: 10 | train acc: 65.03399658203125 | test acc: 55.900001525878906\n",
      "\n",
      "Epoch: 11\n",
      "0 391 Loss: 0.951 | Acc: 71.094% (91/128)\n",
      "0 79 Loss: 1.314 | Acc: 64.844% (83/128)\n",
      "Saving..\n",
      "Epoch: 11 | train acc: 67.05000305175781 | test acc: 60.2400016784668\n",
      "\n",
      "Epoch: 12\n",
      "0 391 Loss: 0.881 | Acc: 75.000% (96/128)\n",
      "0 79 Loss: 1.554 | Acc: 58.594% (75/128)\n",
      "Epoch: 12 | train acc: 69.61199951171875 | test acc: 59.16999816894531\n",
      "\n",
      "Epoch: 13\n",
      "0 391 Loss: 0.673 | Acc: 83.594% (107/128)\n",
      "0 79 Loss: 1.420 | Acc: 60.156% (77/128)\n",
      "Saving..\n",
      "Epoch: 13 | train acc: 71.11000061035156 | test acc: 61.459999084472656\n",
      "\n",
      "Epoch: 14\n",
      "0 391 Loss: 0.798 | Acc: 72.656% (93/128)\n",
      "0 79 Loss: 1.235 | Acc: 65.625% (84/128)\n",
      "Epoch: 14 | train acc: 72.77200317382812 | test acc: 59.63999938964844\n",
      "\n",
      "Epoch: 15\n",
      "0 391 Loss: 0.715 | Acc: 75.781% (97/128)\n",
      "0 79 Loss: 1.303 | Acc: 62.500% (80/128)\n",
      "Saving..\n",
      "Epoch: 15 | train acc: 74.46199798583984 | test acc: 62.4900016784668\n",
      "\n",
      "Epoch: 16\n",
      "0 391 Loss: 0.861 | Acc: 77.344% (99/128)\n",
      "0 79 Loss: 1.306 | Acc: 61.719% (79/128)\n",
      "Epoch: 16 | train acc: 75.50800323486328 | test acc: 62.40999984741211\n",
      "\n",
      "Epoch: 17\n",
      "0 391 Loss: 0.582 | Acc: 82.812% (106/128)\n",
      "0 79 Loss: 1.336 | Acc: 64.062% (82/128)\n",
      "Saving..\n",
      "Epoch: 17 | train acc: 77.0979995727539 | test acc: 62.529998779296875\n",
      "\n",
      "Epoch: 18\n",
      "0 391 Loss: 0.466 | Acc: 85.938% (110/128)\n",
      "0 79 Loss: 1.343 | Acc: 63.281% (81/128)\n",
      "Epoch: 18 | train acc: 78.4739990234375 | test acc: 61.79999923706055\n",
      "\n",
      "Epoch: 19\n",
      "0 391 Loss: 0.402 | Acc: 86.719% (111/128)\n",
      "0 79 Loss: 1.208 | Acc: 67.188% (86/128)\n",
      "Saving..\n",
      "Epoch: 19 | train acc: 79.0979995727539 | test acc: 63.290000915527344\n",
      "\n",
      "Epoch: 20\n",
      "0 391 Loss: 0.588 | Acc: 80.469% (103/128)\n",
      "0 79 Loss: 1.496 | Acc: 65.625% (84/128)\n",
      "Epoch: 20 | train acc: 80.43399810791016 | test acc: 59.40999984741211\n",
      "\n",
      "Epoch: 21\n",
      "0 391 Loss: 0.535 | Acc: 81.250% (104/128)\n",
      "0 79 Loss: 1.301 | Acc: 66.406% (85/128)\n",
      "Saving..\n",
      "Epoch: 21 | train acc: 80.98999786376953 | test acc: 63.5\n",
      "\n",
      "Epoch: 22\n",
      "0 391 Loss: 0.590 | Acc: 79.688% (102/128)\n",
      "0 79 Loss: 1.250 | Acc: 64.844% (83/128)\n",
      "Epoch: 22 | train acc: 81.99400329589844 | test acc: 63.130001068115234\n",
      "\n",
      "Epoch: 23\n",
      "0 391 Loss: 0.462 | Acc: 86.719% (111/128)\n",
      "0 79 Loss: 1.314 | Acc: 71.875% (92/128)\n",
      "Epoch: 23 | train acc: 83.11199951171875 | test acc: 63.38999938964844\n",
      "\n",
      "Epoch: 24\n",
      "0 391 Loss: 0.501 | Acc: 83.594% (107/128)\n",
      "0 79 Loss: 1.444 | Acc: 66.406% (85/128)\n",
      "Saving..\n",
      "Epoch: 24 | train acc: 83.85800170898438 | test acc: 63.720001220703125\n",
      "\n",
      "Epoch: 25\n",
      "0 391 Loss: 0.641 | Acc: 75.781% (97/128)\n",
      "0 79 Loss: 1.533 | Acc: 64.844% (83/128)\n",
      "Saving..\n",
      "Epoch: 25 | train acc: 84.34200286865234 | test acc: 63.7400016784668\n",
      "\n",
      "Epoch: 26\n",
      "0 391 Loss: 0.376 | Acc: 86.719% (111/128)\n",
      "0 79 Loss: 1.238 | Acc: 68.750% (88/128)\n",
      "Epoch: 26 | train acc: 85.04399871826172 | test acc: 63.22999954223633\n",
      "\n",
      "Epoch: 27\n",
      "0 391 Loss: 0.368 | Acc: 86.719% (111/128)\n",
      "0 79 Loss: 1.504 | Acc: 67.969% (87/128)\n",
      "Saving..\n",
      "Epoch: 27 | train acc: 85.62200164794922 | test acc: 64.4000015258789\n",
      "\n",
      "Epoch: 28\n",
      "0 391 Loss: 0.374 | Acc: 88.281% (113/128)\n",
      "0 79 Loss: 1.393 | Acc: 69.531% (89/128)\n",
      "Epoch: 28 | train acc: 86.0719985961914 | test acc: 62.77000045776367\n",
      "\n",
      "Epoch: 29\n",
      "0 391 Loss: 0.336 | Acc: 87.500% (112/128)\n",
      "0 79 Loss: 1.364 | Acc: 69.531% (89/128)\n",
      "Epoch: 29 | train acc: 86.75800323486328 | test acc: 63.90999984741211\n",
      "\n",
      "Epoch: 30\n",
      "0 391 Loss: 0.395 | Acc: 88.281% (113/128)\n",
      "0 79 Loss: 1.513 | Acc: 66.406% (85/128)\n",
      "Epoch: 30 | train acc: 87.07599639892578 | test acc: 63.75\n",
      "\n",
      "Epoch: 31\n",
      "0 391 Loss: 0.326 | Acc: 90.625% (116/128)\n",
      "0 79 Loss: 1.534 | Acc: 67.188% (86/128)\n",
      "Epoch: 31 | train acc: 87.36000061035156 | test acc: 63.119998931884766\n",
      "\n",
      "Epoch: 32\n",
      "0 391 Loss: 0.406 | Acc: 85.938% (110/128)\n",
      "0 79 Loss: 1.581 | Acc: 67.969% (87/128)\n",
      "Epoch: 32 | train acc: 87.95800018310547 | test acc: 63.52000045776367\n",
      "\n",
      "Epoch: 33\n",
      "0 391 Loss: 0.219 | Acc: 93.750% (120/128)\n",
      "0 79 Loss: 1.556 | Acc: 68.750% (88/128)\n",
      "Epoch: 33 | train acc: 88.33399963378906 | test acc: 64.08999633789062\n",
      "\n",
      "Epoch: 34\n",
      "0 391 Loss: 0.314 | Acc: 89.844% (115/128)\n",
      "0 79 Loss: 1.579 | Acc: 67.188% (86/128)\n",
      "Epoch: 34 | train acc: 88.83399963378906 | test acc: 63.060001373291016\n",
      "\n",
      "Epoch: 35\n",
      "0 391 Loss: 0.290 | Acc: 91.406% (117/128)\n",
      "0 79 Loss: 1.294 | Acc: 73.438% (94/128)\n",
      "Saving..\n",
      "Epoch: 35 | train acc: 88.77999877929688 | test acc: 65.52999877929688\n",
      "\n",
      "Epoch: 36\n",
      "0 391 Loss: 0.252 | Acc: 91.406% (117/128)\n",
      "0 79 Loss: 1.249 | Acc: 70.312% (90/128)\n",
      "Epoch: 36 | train acc: 89.58999633789062 | test acc: 63.650001525878906\n",
      "\n",
      "Epoch: 37\n",
      "0 391 Loss: 0.281 | Acc: 89.844% (115/128)\n",
      "0 79 Loss: 1.379 | Acc: 70.312% (90/128)\n",
      "Epoch: 37 | train acc: 89.20800018310547 | test acc: 65.26000213623047\n",
      "\n",
      "Epoch: 38\n",
      "0 391 Loss: 0.287 | Acc: 89.062% (114/128)\n",
      "0 79 Loss: 1.398 | Acc: 70.312% (90/128)\n",
      "Epoch: 38 | train acc: 89.91000366210938 | test acc: 65.27999877929688\n",
      "\n",
      "Epoch: 39\n",
      "0 391 Loss: 0.381 | Acc: 89.844% (115/128)\n",
      "0 79 Loss: 1.415 | Acc: 71.875% (92/128)\n",
      "Epoch: 39 | train acc: 90.0479965209961 | test acc: 65.18000030517578\n",
      "\n",
      "Epoch: 40\n",
      "0 391 Loss: 0.270 | Acc: 89.844% (115/128)\n",
      "0 79 Loss: 1.435 | Acc: 66.406% (85/128)\n",
      "Epoch: 40 | train acc: 90.00399780273438 | test acc: 64.45999908447266\n",
      "\n",
      "Epoch: 41\n",
      "0 391 Loss: 0.202 | Acc: 92.969% (119/128)\n",
      "0 79 Loss: 1.346 | Acc: 73.438% (94/128)\n",
      "Epoch: 41 | train acc: 90.14399719238281 | test acc: 65.20999908447266\n",
      "\n",
      "Epoch: 42\n",
      "0 391 Loss: 0.223 | Acc: 93.750% (120/128)\n",
      "0 79 Loss: 1.413 | Acc: 67.188% (86/128)\n",
      "Epoch: 42 | train acc: 90.51200103759766 | test acc: 65.05000305175781\n",
      "\n",
      "Epoch: 43\n",
      "0 391 Loss: 0.290 | Acc: 89.844% (115/128)\n",
      "0 79 Loss: 1.609 | Acc: 66.406% (85/128)\n",
      "Epoch: 43 | train acc: 90.6780014038086 | test acc: 63.54999923706055\n",
      "\n",
      "Epoch: 44\n",
      "0 391 Loss: 0.363 | Acc: 85.156% (109/128)\n",
      "0 79 Loss: 1.613 | Acc: 67.969% (87/128)\n",
      "Epoch: 44 | train acc: 90.75800323486328 | test acc: 64.29000091552734\n",
      "\n",
      "Epoch: 45\n",
      "0 391 Loss: 0.161 | Acc: 96.875% (124/128)\n",
      "0 79 Loss: 1.672 | Acc: 70.312% (90/128)\n",
      "Epoch: 45 | train acc: 90.74800109863281 | test acc: 63.86000061035156\n",
      "\n",
      "Epoch: 46\n",
      "0 391 Loss: 0.230 | Acc: 92.188% (118/128)\n",
      "0 79 Loss: 1.523 | Acc: 66.406% (85/128)\n",
      "Epoch: 46 | train acc: 90.88200378417969 | test acc: 64.83000183105469\n",
      "\n",
      "Epoch: 47\n",
      "0 391 Loss: 0.146 | Acc: 95.312% (122/128)\n",
      "0 79 Loss: 1.372 | Acc: 73.438% (94/128)\n",
      "Epoch: 47 | train acc: 91.38999938964844 | test acc: 63.65999984741211\n",
      "\n",
      "Epoch: 48\n",
      "0 391 Loss: 0.294 | Acc: 89.062% (114/128)\n",
      "0 79 Loss: 1.776 | Acc: 67.188% (86/128)\n",
      "Epoch: 48 | train acc: 91.20600128173828 | test acc: 63.20000076293945\n",
      "\n",
      "Epoch: 49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 391 Loss: 0.294 | Acc: 89.062% (114/128)\n",
      "0 79 Loss: 1.562 | Acc: 68.750% (88/128)\n",
      "Epoch: 49 | train acc: 91.38999938964844 | test acc: 64.58999633789062\n",
      "\n",
      "Epoch: 50\n",
      "0 391 Loss: 0.293 | Acc: 89.844% (115/128)\n",
      "0 79 Loss: 1.523 | Acc: 71.094% (91/128)\n",
      "Epoch: 50 | train acc: 91.71199798583984 | test acc: 64.4800033569336\n",
      "\n",
      "Epoch: 51\n",
      "0 391 Loss: 0.200 | Acc: 92.969% (119/128)\n",
      "0 79 Loss: 1.858 | Acc: 71.875% (92/128)\n",
      "Epoch: 51 | train acc: 91.41799926757812 | test acc: 64.51000213623047\n",
      "\n",
      "Epoch: 52\n",
      "0 391 Loss: 0.348 | Acc: 89.844% (115/128)\n",
      "0 79 Loss: 1.526 | Acc: 65.625% (84/128)\n",
      "Epoch: 52 | train acc: 91.40399932861328 | test acc: 64.47000122070312\n",
      "\n",
      "Epoch: 53\n",
      "0 391 Loss: 0.128 | Acc: 96.094% (123/128)\n",
      "0 79 Loss: 1.675 | Acc: 67.188% (86/128)\n",
      "Epoch: 53 | train acc: 91.77200317382812 | test acc: 63.290000915527344\n",
      "\n",
      "Epoch: 54\n",
      "0 391 Loss: 0.257 | Acc: 92.188% (118/128)\n",
      "0 79 Loss: 1.581 | Acc: 67.969% (87/128)\n",
      "Epoch: 54 | train acc: 91.61000061035156 | test acc: 63.72999954223633\n",
      "\n",
      "Epoch: 55\n",
      "0 391 Loss: 0.146 | Acc: 97.656% (125/128)\n",
      "0 79 Loss: 1.692 | Acc: 67.188% (86/128)\n",
      "Saving..\n",
      "Epoch: 55 | train acc: 91.49800109863281 | test acc: 65.62999725341797\n",
      "\n",
      "Epoch: 56\n",
      "0 391 Loss: 0.279 | Acc: 89.844% (115/128)\n",
      "0 79 Loss: 1.443 | Acc: 70.312% (90/128)\n",
      "Epoch: 56 | train acc: 92.08200073242188 | test acc: 65.02999877929688\n",
      "\n",
      "Epoch: 57\n",
      "0 391 Loss: 0.157 | Acc: 96.875% (124/128)\n",
      "0 79 Loss: 1.810 | Acc: 65.625% (84/128)\n",
      "Epoch: 57 | train acc: 91.6259994506836 | test acc: 64.23999786376953\n",
      "\n",
      "Epoch: 58\n",
      "0 391 Loss: 0.247 | Acc: 91.406% (117/128)\n",
      "0 79 Loss: 2.137 | Acc: 60.938% (78/128)\n",
      "Epoch: 58 | train acc: 91.947998046875 | test acc: 62.91999816894531\n",
      "\n",
      "Epoch: 59\n",
      "0 391 Loss: 0.293 | Acc: 90.625% (116/128)\n",
      "0 79 Loss: 1.473 | Acc: 67.188% (86/128)\n",
      "Epoch: 59 | train acc: 91.86000061035156 | test acc: 65.30000305175781\n",
      "\n",
      "Epoch: 60\n",
      "0 391 Loss: 0.141 | Acc: 96.875% (124/128)\n",
      "0 79 Loss: 1.343 | Acc: 71.875% (92/128)\n",
      "Saving..\n",
      "Epoch: 60 | train acc: 92.37999725341797 | test acc: 66.48999786376953\n",
      "\n",
      "Epoch: 61\n",
      "0 391 Loss: 0.220 | Acc: 92.969% (119/128)\n",
      "0 79 Loss: 1.532 | Acc: 67.188% (86/128)\n",
      "Epoch: 61 | train acc: 92.28600311279297 | test acc: 64.94999694824219\n",
      "\n",
      "Epoch: 62\n",
      "0 391 Loss: 0.114 | Acc: 96.875% (124/128)\n",
      "0 79 Loss: 2.109 | Acc: 61.719% (79/128)\n",
      "Epoch: 62 | train acc: 92.0999984741211 | test acc: 63.279998779296875\n",
      "\n",
      "Epoch: 63\n",
      "0 391 Loss: 0.282 | Acc: 90.625% (116/128)\n",
      "0 79 Loss: 1.540 | Acc: 67.188% (86/128)\n",
      "Epoch: 63 | train acc: 92.1719970703125 | test acc: 63.06999969482422\n",
      "\n",
      "Epoch: 64\n",
      "0 391 Loss: 0.254 | Acc: 92.188% (118/128)\n",
      "0 79 Loss: 1.314 | Acc: 72.656% (93/128)\n",
      "Saving..\n",
      "Epoch: 64 | train acc: 92.29000091552734 | test acc: 66.70999908447266\n",
      "\n",
      "Epoch: 65\n",
      "0 391 Loss: 0.258 | Acc: 91.406% (117/128)\n",
      "0 79 Loss: 1.524 | Acc: 70.312% (90/128)\n",
      "Epoch: 65 | train acc: 92.4540023803711 | test acc: 63.779998779296875\n",
      "\n",
      "Epoch: 66\n",
      "0 391 Loss: 0.181 | Acc: 92.188% (118/128)\n",
      "0 79 Loss: 1.564 | Acc: 69.531% (89/128)\n",
      "Epoch: 66 | train acc: 92.10800170898438 | test acc: 64.56999969482422\n",
      "\n",
      "Epoch: 67\n",
      "0 391 Loss: 0.265 | Acc: 92.188% (118/128)\n",
      "0 79 Loss: 1.531 | Acc: 71.875% (92/128)\n",
      "Epoch: 67 | train acc: 92.00199890136719 | test acc: 64.76000213623047\n",
      "\n",
      "Epoch: 68\n",
      "0 391 Loss: 0.135 | Acc: 96.875% (124/128)\n",
      "0 79 Loss: 1.776 | Acc: 69.531% (89/128)\n",
      "Epoch: 68 | train acc: 92.16400146484375 | test acc: 64.73999786376953\n",
      "\n",
      "Epoch: 69\n",
      "0 391 Loss: 0.138 | Acc: 96.094% (123/128)\n",
      "0 79 Loss: 1.672 | Acc: 68.750% (88/128)\n",
      "Epoch: 69 | train acc: 92.48600006103516 | test acc: 63.65999984741211\n",
      "\n",
      "Epoch: 70\n",
      "0 391 Loss: 0.179 | Acc: 95.312% (122/128)\n",
      "0 79 Loss: 1.395 | Acc: 73.438% (94/128)\n",
      "Epoch: 70 | train acc: 92.08799743652344 | test acc: 64.04000091552734\n",
      "\n",
      "Epoch: 71\n",
      "0 391 Loss: 0.109 | Acc: 96.875% (124/128)\n",
      "0 79 Loss: 1.834 | Acc: 64.844% (83/128)\n",
      "Epoch: 71 | train acc: 92.2300033569336 | test acc: 62.61000061035156\n",
      "\n",
      "Epoch: 72\n",
      "0 391 Loss: 0.137 | Acc: 94.531% (121/128)\n",
      "0 79 Loss: 1.855 | Acc: 65.625% (84/128)\n",
      "Epoch: 72 | train acc: 92.89199829101562 | test acc: 63.0099983215332\n",
      "\n",
      "Epoch: 73\n",
      "0 391 Loss: 0.112 | Acc: 96.875% (124/128)\n",
      "0 79 Loss: 1.802 | Acc: 65.625% (84/128)\n",
      "Epoch: 73 | train acc: 92.25399780273438 | test acc: 64.48999786376953\n",
      "\n",
      "Epoch: 74\n",
      "0 391 Loss: 0.191 | Acc: 92.969% (119/128)\n",
      "0 79 Loss: 1.761 | Acc: 68.750% (88/128)\n",
      "Epoch: 74 | train acc: 92.62999725341797 | test acc: 64.16000366210938\n",
      "\n",
      "Epoch: 75\n",
      "0 391 Loss: 0.168 | Acc: 92.969% (119/128)\n",
      "0 79 Loss: 1.619 | Acc: 67.969% (87/128)\n",
      "Epoch: 75 | train acc: 93.0199966430664 | test acc: 65.36000061035156\n",
      "\n",
      "Epoch: 76\n",
      "0 391 Loss: 0.197 | Acc: 92.969% (119/128)\n",
      "0 79 Loss: 1.566 | Acc: 72.656% (93/128)\n",
      "Epoch: 76 | train acc: 92.6240005493164 | test acc: 65.41999816894531\n",
      "\n",
      "Epoch: 77\n",
      "0 391 Loss: 0.194 | Acc: 93.750% (120/128)\n",
      "0 79 Loss: 1.685 | Acc: 64.844% (83/128)\n",
      "Epoch: 77 | train acc: 92.43199920654297 | test acc: 64.75\n",
      "\n",
      "Epoch: 78\n",
      "0 391 Loss: 0.257 | Acc: 92.188% (118/128)\n",
      "0 79 Loss: 1.503 | Acc: 68.750% (88/128)\n",
      "Epoch: 78 | train acc: 92.62799835205078 | test acc: 64.0\n",
      "\n",
      "Epoch: 79\n",
      "0 391 Loss: 0.275 | Acc: 92.188% (118/128)\n",
      "0 79 Loss: 1.320 | Acc: 70.312% (90/128)\n",
      "Epoch: 79 | train acc: 92.65599822998047 | test acc: 63.630001068115234\n",
      "\n",
      "Epoch: 80\n",
      "0 391 Loss: 0.220 | Acc: 93.750% (120/128)\n",
      "0 79 Loss: 1.660 | Acc: 64.062% (82/128)\n",
      "Epoch: 80 | train acc: 92.44000244140625 | test acc: 64.06999969482422\n",
      "\n",
      "Epoch: 81\n",
      "0 391 Loss: 0.233 | Acc: 92.188% (118/128)\n",
      "0 79 Loss: 1.593 | Acc: 71.875% (92/128)\n",
      "Epoch: 81 | train acc: 92.7300033569336 | test acc: 65.6500015258789\n",
      "\n",
      "Epoch: 82\n",
      "0 391 Loss: 0.195 | Acc: 95.312% (122/128)\n",
      "0 79 Loss: 1.585 | Acc: 68.750% (88/128)\n",
      "Epoch: 82 | train acc: 92.94400024414062 | test acc: 64.9800033569336\n",
      "\n",
      "Epoch: 83\n",
      "0 391 Loss: 0.242 | Acc: 91.406% (117/128)\n",
      "0 79 Loss: 1.818 | Acc: 65.625% (84/128)\n",
      "Epoch: 83 | train acc: 92.70600128173828 | test acc: 64.66999816894531\n",
      "\n",
      "Epoch: 84\n",
      "0 391 Loss: 0.189 | Acc: 94.531% (121/128)\n",
      "0 79 Loss: 1.700 | Acc: 71.875% (92/128)\n",
      "Epoch: 84 | train acc: 93.81400299072266 | test acc: 65.77999877929688\n",
      "\n",
      "Epoch: 85\n",
      "0 391 Loss: 0.137 | Acc: 94.531% (121/128)\n",
      "0 79 Loss: 1.935 | Acc: 64.062% (82/128)\n",
      "Epoch: 85 | train acc: 92.49199676513672 | test acc: 62.63999938964844\n",
      "\n",
      "Epoch: 86\n",
      "0 391 Loss: 0.261 | Acc: 91.406% (117/128)\n",
      "0 79 Loss: 1.591 | Acc: 68.750% (88/128)\n",
      "Epoch: 86 | train acc: 92.60199737548828 | test acc: 64.36000061035156\n",
      "\n",
      "Epoch: 87\n",
      "0 391 Loss: 0.143 | Acc: 96.094% (123/128)\n",
      "0 79 Loss: 1.859 | Acc: 67.188% (86/128)\n",
      "Epoch: 87 | train acc: 93.20600128173828 | test acc: 63.7400016784668\n",
      "\n",
      "Epoch: 88\n",
      "0 391 Loss: 0.233 | Acc: 92.969% (119/128)\n",
      "0 79 Loss: 1.997 | Acc: 64.844% (83/128)\n",
      "Epoch: 88 | train acc: 93.18399810791016 | test acc: 65.55000305175781\n",
      "\n",
      "Epoch: 89\n",
      "0 391 Loss: 0.217 | Acc: 90.625% (116/128)\n",
      "0 79 Loss: 1.962 | Acc: 70.312% (90/128)\n",
      "Epoch: 89 | train acc: 92.552001953125 | test acc: 64.16999816894531\n",
      "\n",
      "Epoch: 90\n",
      "0 391 Loss: 0.249 | Acc: 92.188% (118/128)\n",
      "0 79 Loss: 1.731 | Acc: 64.062% (82/128)\n",
      "Epoch: 90 | train acc: 92.46199798583984 | test acc: 64.80000305175781\n",
      "\n",
      "Epoch: 91\n",
      "0 391 Loss: 0.125 | Acc: 95.312% (122/128)\n",
      "0 79 Loss: 1.464 | Acc: 70.312% (90/128)\n",
      "Epoch: 91 | train acc: 93.11199951171875 | test acc: 65.38999938964844\n",
      "\n",
      "Epoch: 92\n",
      "0 391 Loss: 0.189 | Acc: 95.312% (122/128)\n",
      "0 79 Loss: 1.746 | Acc: 67.969% (87/128)\n",
      "Epoch: 92 | train acc: 93.3759994506836 | test acc: 65.05000305175781\n",
      "\n",
      "Epoch: 93\n",
      "0 391 Loss: 0.180 | Acc: 92.188% (118/128)\n",
      "0 79 Loss: 1.477 | Acc: 69.531% (89/128)\n",
      "Epoch: 93 | train acc: 92.52400207519531 | test acc: 64.80000305175781\n",
      "\n",
      "Epoch: 94\n",
      "0 391 Loss: 0.210 | Acc: 92.969% (119/128)\n",
      "0 79 Loss: 1.774 | Acc: 71.094% (91/128)\n",
      "Saving..\n",
      "Epoch: 94 | train acc: 93.25 | test acc: 66.8499984741211\n",
      "\n",
      "Epoch: 95\n",
      "0 391 Loss: 0.167 | Acc: 93.750% (120/128)\n",
      "0 79 Loss: 1.450 | Acc: 74.219% (95/128)\n",
      "Epoch: 95 | train acc: 93.22200012207031 | test acc: 65.73999786376953\n",
      "\n",
      "Epoch: 96\n",
      "0 391 Loss: 0.206 | Acc: 92.188% (118/128)\n",
      "0 79 Loss: 1.521 | Acc: 67.969% (87/128)\n",
      "Epoch: 96 | train acc: 93.49800109863281 | test acc: 65.48999786376953\n",
      "\n",
      "Epoch: 97\n",
      "0 391 Loss: 0.105 | Acc: 98.438% (126/128)\n",
      "0 79 Loss: 1.498 | Acc: 68.750% (88/128)\n",
      "Epoch: 97 | train acc: 92.88800048828125 | test acc: 66.0\n",
      "\n",
      "Epoch: 98\n",
      "0 391 Loss: 0.347 | Acc: 88.281% (113/128)\n",
      "0 79 Loss: 1.831 | Acc: 70.312% (90/128)\n",
      "Epoch: 98 | train acc: 92.80599975585938 | test acc: 65.47000122070312\n",
      "\n",
      "Epoch: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 391 Loss: 0.218 | Acc: 92.969% (119/128)\n",
      "0 79 Loss: 1.403 | Acc: 75.000% (96/128)\n",
      "Epoch: 99 | train acc: 92.88600158691406 | test acc: 65.0\n",
      "\n",
      "Epoch: 100\n",
      "0 391 Loss: 0.165 | Acc: 95.312% (122/128)\n",
      "0 79 Loss: 1.312 | Acc: 73.438% (94/128)\n",
      "Saving..\n",
      "Epoch: 100 | train acc: 97.73999786376953 | test acc: 71.94999694824219\n",
      "\n",
      "Epoch: 101\n",
      "0 391 Loss: 0.024 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.292 | Acc: 75.000% (96/128)\n",
      "Saving..\n",
      "Epoch: 101 | train acc: 99.19599914550781 | test acc: 72.69999694824219\n",
      "\n",
      "Epoch: 102\n",
      "0 391 Loss: 0.015 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.289 | Acc: 73.438% (94/128)\n",
      "Saving..\n",
      "Epoch: 102 | train acc: 99.45999908447266 | test acc: 72.83000183105469\n",
      "\n",
      "Epoch: 103\n",
      "0 391 Loss: 0.017 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.253 | Acc: 72.656% (93/128)\n",
      "Saving..\n",
      "Epoch: 103 | train acc: 99.5719985961914 | test acc: 72.91999816894531\n",
      "\n",
      "Epoch: 104\n",
      "0 391 Loss: 0.015 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.261 | Acc: 73.438% (94/128)\n",
      "Saving..\n",
      "Epoch: 104 | train acc: 99.66799926757812 | test acc: 73.41999816894531\n",
      "\n",
      "Epoch: 105\n",
      "0 391 Loss: 0.010 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.254 | Acc: 72.656% (93/128)\n",
      "Epoch: 105 | train acc: 99.73799896240234 | test acc: 73.23999786376953\n",
      "\n",
      "Epoch: 106\n",
      "0 391 Loss: 0.019 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.247 | Acc: 72.656% (93/128)\n",
      "Epoch: 106 | train acc: 99.75199890136719 | test acc: 73.33999633789062\n",
      "\n",
      "Epoch: 107\n",
      "0 391 Loss: 0.011 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.252 | Acc: 75.000% (96/128)\n",
      "Epoch: 107 | train acc: 99.75599670410156 | test acc: 73.4000015258789\n",
      "\n",
      "Epoch: 108\n",
      "0 391 Loss: 0.019 | Acc: 99.219% (127/128)\n",
      "0 79 Loss: 1.232 | Acc: 71.094% (91/128)\n",
      "Epoch: 108 | train acc: 99.8239974975586 | test acc: 73.4000015258789\n",
      "\n",
      "Epoch: 109\n",
      "0 391 Loss: 0.009 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.260 | Acc: 71.875% (92/128)\n",
      "Saving..\n",
      "Epoch: 109 | train acc: 99.83999633789062 | test acc: 73.5\n",
      "\n",
      "Epoch: 110\n",
      "0 391 Loss: 0.008 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.250 | Acc: 73.438% (94/128)\n",
      "Saving..\n",
      "Epoch: 110 | train acc: 99.85199737548828 | test acc: 73.73999786376953\n",
      "\n",
      "Epoch: 111\n",
      "0 391 Loss: 0.014 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.231 | Acc: 71.875% (92/128)\n",
      "Epoch: 111 | train acc: 99.89399719238281 | test acc: 73.66999816894531\n",
      "\n",
      "Epoch: 112\n",
      "0 391 Loss: 0.006 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.248 | Acc: 72.656% (93/128)\n",
      "Epoch: 112 | train acc: 99.8740005493164 | test acc: 73.5\n",
      "\n",
      "Epoch: 113\n",
      "0 391 Loss: 0.007 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.251 | Acc: 74.219% (95/128)\n",
      "Epoch: 113 | train acc: 99.89600372314453 | test acc: 73.44000244140625\n",
      "\n",
      "Epoch: 114\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.241 | Acc: 75.000% (96/128)\n",
      "Epoch: 114 | train acc: 99.88999938964844 | test acc: 73.58000183105469\n",
      "\n",
      "Epoch: 115\n",
      "0 391 Loss: 0.011 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.240 | Acc: 74.219% (95/128)\n",
      "Saving..\n",
      "Epoch: 115 | train acc: 99.90799713134766 | test acc: 73.8499984741211\n",
      "\n",
      "Epoch: 116\n",
      "0 391 Loss: 0.032 | Acc: 99.219% (127/128)\n",
      "0 79 Loss: 1.240 | Acc: 74.219% (95/128)\n",
      "Epoch: 116 | train acc: 99.92400360107422 | test acc: 73.66000366210938\n",
      "\n",
      "Epoch: 117\n",
      "0 391 Loss: 0.009 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.230 | Acc: 75.000% (96/128)\n",
      "Epoch: 117 | train acc: 99.91200256347656 | test acc: 73.72000122070312\n",
      "\n",
      "Epoch: 118\n",
      "0 391 Loss: 0.011 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.237 | Acc: 73.438% (94/128)\n",
      "Epoch: 118 | train acc: 99.93199920654297 | test acc: 73.58999633789062\n",
      "\n",
      "Epoch: 119\n",
      "0 391 Loss: 0.009 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.203 | Acc: 72.656% (93/128)\n",
      "Epoch: 119 | train acc: 99.94200134277344 | test acc: 73.66999816894531\n",
      "\n",
      "Epoch: 120\n",
      "0 391 Loss: 0.008 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.222 | Acc: 73.438% (94/128)\n",
      "Epoch: 120 | train acc: 99.93199920654297 | test acc: 73.69000244140625\n",
      "\n",
      "Epoch: 121\n",
      "0 391 Loss: 0.007 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.243 | Acc: 74.219% (95/128)\n",
      "Epoch: 121 | train acc: 99.9219970703125 | test acc: 73.80999755859375\n",
      "\n",
      "Epoch: 122\n",
      "0 391 Loss: 0.006 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.256 | Acc: 73.438% (94/128)\n",
      "Epoch: 122 | train acc: 99.9260025024414 | test acc: 73.69999694824219\n",
      "\n",
      "Epoch: 123\n",
      "0 391 Loss: 0.004 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.243 | Acc: 72.656% (93/128)\n",
      "Epoch: 123 | train acc: 99.91600036621094 | test acc: 73.80999755859375\n",
      "\n",
      "Epoch: 124\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.239 | Acc: 75.000% (96/128)\n",
      "Saving..\n",
      "Epoch: 124 | train acc: 99.96600341796875 | test acc: 73.86000061035156\n",
      "\n",
      "Epoch: 125\n",
      "0 391 Loss: 0.010 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.238 | Acc: 73.438% (94/128)\n",
      "Saving..\n",
      "Epoch: 125 | train acc: 99.94599914550781 | test acc: 73.88999938964844\n",
      "\n",
      "Epoch: 126\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.241 | Acc: 73.438% (94/128)\n",
      "Saving..\n",
      "Epoch: 126 | train acc: 99.9540023803711 | test acc: 73.91999816894531\n",
      "\n",
      "Epoch: 127\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.205 | Acc: 73.438% (94/128)\n",
      "Saving..\n",
      "Epoch: 127 | train acc: 99.9520034790039 | test acc: 73.94000244140625\n",
      "\n",
      "Epoch: 128\n",
      "0 391 Loss: 0.007 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.208 | Acc: 73.438% (94/128)\n",
      "Epoch: 128 | train acc: 99.95600128173828 | test acc: 73.80000305175781\n",
      "\n",
      "Epoch: 129\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.215 | Acc: 74.219% (95/128)\n",
      "Saving..\n",
      "Epoch: 129 | train acc: 99.94400024414062 | test acc: 74.01000213623047\n",
      "\n",
      "Epoch: 130\n",
      "0 391 Loss: 0.008 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.222 | Acc: 74.219% (95/128)\n",
      "Epoch: 130 | train acc: 99.95800018310547 | test acc: 73.91000366210938\n",
      "\n",
      "Epoch: 131\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.211 | Acc: 74.219% (95/128)\n",
      "Saving..\n",
      "Epoch: 131 | train acc: 99.96399688720703 | test acc: 74.04000091552734\n",
      "\n",
      "Epoch: 132\n",
      "0 391 Loss: 0.009 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.188 | Acc: 73.438% (94/128)\n",
      "Epoch: 132 | train acc: 99.947998046875 | test acc: 73.87000274658203\n",
      "\n",
      "Epoch: 133\n",
      "0 391 Loss: 0.004 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.197 | Acc: 74.219% (95/128)\n",
      "Epoch: 133 | train acc: 99.95800018310547 | test acc: 73.97000122070312\n",
      "\n",
      "Epoch: 134\n",
      "0 391 Loss: 0.008 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.209 | Acc: 74.219% (95/128)\n",
      "Epoch: 134 | train acc: 99.9540023803711 | test acc: 73.95999908447266\n",
      "\n",
      "Epoch: 135\n",
      "0 391 Loss: 0.004 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.216 | Acc: 74.219% (95/128)\n",
      "Epoch: 135 | train acc: 99.94999694824219 | test acc: 73.91999816894531\n",
      "\n",
      "Epoch: 136\n",
      "0 391 Loss: 0.010 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.207 | Acc: 73.438% (94/128)\n",
      "Saving..\n",
      "Epoch: 136 | train acc: 99.94599914550781 | test acc: 74.20999908447266\n",
      "\n",
      "Epoch: 137\n",
      "0 391 Loss: 0.013 | Acc: 99.219% (127/128)\n",
      "0 79 Loss: 1.213 | Acc: 74.219% (95/128)\n",
      "Epoch: 137 | train acc: 99.94999694824219 | test acc: 74.12999725341797\n",
      "\n",
      "Epoch: 138\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.213 | Acc: 75.000% (96/128)\n",
      "Epoch: 138 | train acc: 99.96199798583984 | test acc: 74.11000061035156\n",
      "\n",
      "Epoch: 139\n",
      "0 391 Loss: 0.004 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.199 | Acc: 75.000% (96/128)\n",
      "Epoch: 139 | train acc: 99.95800018310547 | test acc: 74.08000183105469\n",
      "\n",
      "Epoch: 140\n",
      "0 391 Loss: 0.006 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.200 | Acc: 74.219% (95/128)\n",
      "Epoch: 140 | train acc: 99.94200134277344 | test acc: 73.98999786376953\n",
      "\n",
      "Epoch: 141\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.210 | Acc: 74.219% (95/128)\n",
      "Epoch: 141 | train acc: 99.94999694824219 | test acc: 74.11000061035156\n",
      "\n",
      "Epoch: 142\n",
      "0 391 Loss: 0.018 | Acc: 99.219% (127/128)\n",
      "0 79 Loss: 1.181 | Acc: 75.000% (96/128)\n",
      "Epoch: 142 | train acc: 99.96399688720703 | test acc: 74.01000213623047\n",
      "\n",
      "Epoch: 143\n",
      "0 391 Loss: 0.004 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.196 | Acc: 75.000% (96/128)\n",
      "Epoch: 143 | train acc: 99.9540023803711 | test acc: 74.05999755859375\n",
      "\n",
      "Epoch: 144\n",
      "0 391 Loss: 0.009 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.193 | Acc: 75.000% (96/128)\n",
      "Epoch: 144 | train acc: 99.94999694824219 | test acc: 74.06999969482422\n",
      "\n",
      "Epoch: 145\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.205 | Acc: 74.219% (95/128)\n",
      "Epoch: 145 | train acc: 99.94999694824219 | test acc: 74.20999908447266\n",
      "\n",
      "Epoch: 146\n",
      "0 391 Loss: 0.013 | Acc: 99.219% (127/128)\n",
      "0 79 Loss: 1.178 | Acc: 74.219% (95/128)\n",
      "Saving..\n",
      "Epoch: 146 | train acc: 99.94599914550781 | test acc: 74.22000122070312\n",
      "\n",
      "Epoch: 147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 391 Loss: 0.010 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.169 | Acc: 74.219% (95/128)\n",
      "Saving..\n",
      "Epoch: 147 | train acc: 99.9540023803711 | test acc: 74.25\n",
      "\n",
      "Epoch: 148\n",
      "0 391 Loss: 0.003 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.168 | Acc: 75.000% (96/128)\n",
      "Epoch: 148 | train acc: 99.95600128173828 | test acc: 74.19000244140625\n",
      "\n",
      "Epoch: 149\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.138 | Acc: 75.000% (96/128)\n",
      "Saving..\n",
      "Epoch: 149 | train acc: 99.95600128173828 | test acc: 74.54000091552734\n",
      "\n",
      "Epoch: 150\n",
      "0 391 Loss: 0.004 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.163 | Acc: 75.781% (97/128)\n",
      "Epoch: 150 | train acc: 99.96399688720703 | test acc: 74.33000183105469\n",
      "\n",
      "Epoch: 151\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.153 | Acc: 75.781% (97/128)\n",
      "Epoch: 151 | train acc: 99.95600128173828 | test acc: 74.2300033569336\n",
      "\n",
      "Epoch: 152\n",
      "0 391 Loss: 0.004 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.158 | Acc: 73.438% (94/128)\n",
      "Epoch: 152 | train acc: 99.97599792480469 | test acc: 74.27999877929688\n",
      "\n",
      "Epoch: 153\n",
      "0 391 Loss: 0.007 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.147 | Acc: 75.781% (97/128)\n",
      "Epoch: 153 | train acc: 99.95999908447266 | test acc: 74.29000091552734\n",
      "\n",
      "Epoch: 154\n",
      "0 391 Loss: 0.003 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.157 | Acc: 75.000% (96/128)\n",
      "Epoch: 154 | train acc: 99.96399688720703 | test acc: 74.27999877929688\n",
      "\n",
      "Epoch: 155\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.144 | Acc: 74.219% (95/128)\n",
      "Epoch: 155 | train acc: 99.97000122070312 | test acc: 74.43000030517578\n",
      "\n",
      "Epoch: 156\n",
      "0 391 Loss: 0.006 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.153 | Acc: 75.781% (97/128)\n",
      "Epoch: 156 | train acc: 99.9739990234375 | test acc: 74.22000122070312\n",
      "\n",
      "Epoch: 157\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.163 | Acc: 75.000% (96/128)\n",
      "Epoch: 157 | train acc: 99.96800231933594 | test acc: 74.33999633789062\n",
      "\n",
      "Epoch: 158\n",
      "0 391 Loss: 0.006 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.150 | Acc: 74.219% (95/128)\n",
      "Epoch: 158 | train acc: 99.97000122070312 | test acc: 74.5\n",
      "\n",
      "Epoch: 159\n",
      "0 391 Loss: 0.010 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.142 | Acc: 75.781% (97/128)\n",
      "Epoch: 159 | train acc: 99.96399688720703 | test acc: 74.37000274658203\n",
      "\n",
      "Epoch: 160\n",
      "0 391 Loss: 0.006 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.151 | Acc: 75.781% (97/128)\n",
      "Epoch: 160 | train acc: 99.97000122070312 | test acc: 74.37999725341797\n",
      "\n",
      "Epoch: 161\n",
      "0 391 Loss: 0.003 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.152 | Acc: 75.781% (97/128)\n",
      "Epoch: 161 | train acc: 99.97000122070312 | test acc: 74.31999969482422\n",
      "\n",
      "Epoch: 162\n",
      "0 391 Loss: 0.008 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.141 | Acc: 75.000% (96/128)\n",
      "Epoch: 162 | train acc: 99.96800231933594 | test acc: 74.4000015258789\n",
      "\n",
      "Epoch: 163\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.163 | Acc: 76.562% (98/128)\n",
      "Epoch: 163 | train acc: 99.95800018310547 | test acc: 74.2699966430664\n",
      "\n",
      "Epoch: 164\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.150 | Acc: 74.219% (95/128)\n",
      "Epoch: 164 | train acc: 99.96199798583984 | test acc: 74.4000015258789\n",
      "\n",
      "Epoch: 165\n",
      "0 391 Loss: 0.003 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.153 | Acc: 75.000% (96/128)\n",
      "Epoch: 165 | train acc: 99.97599792480469 | test acc: 74.33999633789062\n",
      "\n",
      "Epoch: 166\n",
      "0 391 Loss: 0.004 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.143 | Acc: 75.000% (96/128)\n",
      "Epoch: 166 | train acc: 99.96399688720703 | test acc: 74.18000030517578\n",
      "\n",
      "Epoch: 167\n",
      "0 391 Loss: 0.006 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.176 | Acc: 75.781% (97/128)\n",
      "Epoch: 167 | train acc: 99.95999908447266 | test acc: 74.33000183105469\n",
      "\n",
      "Epoch: 168\n",
      "0 391 Loss: 0.006 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.144 | Acc: 75.781% (97/128)\n",
      "Epoch: 168 | train acc: 99.97200012207031 | test acc: 74.41000366210938\n",
      "\n",
      "Epoch: 169\n",
      "0 391 Loss: 0.004 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.155 | Acc: 75.781% (97/128)\n",
      "Epoch: 169 | train acc: 99.97200012207031 | test acc: 74.25\n",
      "\n",
      "Epoch: 170\n",
      "0 391 Loss: 0.008 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.153 | Acc: 75.781% (97/128)\n",
      "Epoch: 170 | train acc: 99.97599792480469 | test acc: 74.16999816894531\n",
      "\n",
      "Epoch: 171\n",
      "0 391 Loss: 0.004 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.154 | Acc: 75.781% (97/128)\n",
      "Epoch: 171 | train acc: 99.96199798583984 | test acc: 74.33999633789062\n",
      "\n",
      "Epoch: 172\n",
      "0 391 Loss: 0.004 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.147 | Acc: 75.781% (97/128)\n",
      "Epoch: 172 | train acc: 99.96800231933594 | test acc: 74.36000061035156\n",
      "\n",
      "Epoch: 173\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.146 | Acc: 75.781% (97/128)\n",
      "Epoch: 173 | train acc: 99.97200012207031 | test acc: 74.38999938964844\n",
      "\n",
      "Epoch: 174\n",
      "0 391 Loss: 0.006 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.150 | Acc: 75.781% (97/128)\n",
      "Epoch: 174 | train acc: 99.9800033569336 | test acc: 74.29000091552734\n",
      "\n",
      "Epoch: 175\n",
      "0 391 Loss: 0.004 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.141 | Acc: 75.781% (97/128)\n",
      "Epoch: 175 | train acc: 99.97799682617188 | test acc: 74.23999786376953\n",
      "\n",
      "Epoch: 176\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.154 | Acc: 75.781% (97/128)\n",
      "Epoch: 176 | train acc: 99.96199798583984 | test acc: 74.29000091552734\n",
      "\n",
      "Epoch: 177\n",
      "0 391 Loss: 0.007 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.142 | Acc: 74.219% (95/128)\n",
      "Epoch: 177 | train acc: 99.97799682617188 | test acc: 74.33000183105469\n",
      "\n",
      "Epoch: 178\n",
      "0 391 Loss: 0.003 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.147 | Acc: 75.781% (97/128)\n",
      "Epoch: 178 | train acc: 99.96800231933594 | test acc: 74.26000213623047\n",
      "\n",
      "Epoch: 179\n",
      "0 391 Loss: 0.004 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.153 | Acc: 75.000% (96/128)\n",
      "Epoch: 179 | train acc: 99.96800231933594 | test acc: 74.33999633789062\n",
      "\n",
      "Epoch: 180\n",
      "0 391 Loss: 0.003 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.159 | Acc: 75.000% (96/128)\n",
      "Epoch: 180 | train acc: 99.9739990234375 | test acc: 74.37000274658203\n",
      "\n",
      "Epoch: 181\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.134 | Acc: 74.219% (95/128)\n",
      "Epoch: 181 | train acc: 99.9540023803711 | test acc: 74.29000091552734\n",
      "\n",
      "Epoch: 182\n",
      "0 391 Loss: 0.003 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.160 | Acc: 75.781% (97/128)\n",
      "Epoch: 182 | train acc: 99.9739990234375 | test acc: 74.4000015258789\n",
      "\n",
      "Epoch: 183\n",
      "0 391 Loss: 0.002 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.164 | Acc: 75.000% (96/128)\n",
      "Epoch: 183 | train acc: 99.96800231933594 | test acc: 74.25\n",
      "\n",
      "Epoch: 184\n",
      "0 391 Loss: 0.003 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.164 | Acc: 75.781% (97/128)\n",
      "Epoch: 184 | train acc: 99.9739990234375 | test acc: 74.30000305175781\n",
      "\n",
      "Epoch: 185\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.161 | Acc: 75.781% (97/128)\n",
      "Epoch: 185 | train acc: 99.97799682617188 | test acc: 74.30999755859375\n",
      "\n",
      "Epoch: 186\n",
      "0 391 Loss: 0.004 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.132 | Acc: 75.781% (97/128)\n",
      "Epoch: 186 | train acc: 99.97000122070312 | test acc: 74.25\n",
      "\n",
      "Epoch: 187\n",
      "0 391 Loss: 0.007 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.154 | Acc: 75.000% (96/128)\n",
      "Epoch: 187 | train acc: 99.97000122070312 | test acc: 74.20999908447266\n",
      "\n",
      "Epoch: 188\n",
      "0 391 Loss: 0.007 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.139 | Acc: 75.781% (97/128)\n",
      "Epoch: 188 | train acc: 99.97000122070312 | test acc: 74.30000305175781\n",
      "\n",
      "Epoch: 189\n",
      "0 391 Loss: 0.008 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.145 | Acc: 75.781% (97/128)\n",
      "Epoch: 189 | train acc: 99.96800231933594 | test acc: 74.41000366210938\n",
      "\n",
      "Epoch: 190\n",
      "0 391 Loss: 0.004 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.148 | Acc: 75.781% (97/128)\n",
      "Epoch: 190 | train acc: 99.97200012207031 | test acc: 74.48999786376953\n",
      "\n",
      "Epoch: 191\n",
      "0 391 Loss: 0.006 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.145 | Acc: 75.781% (97/128)\n",
      "Epoch: 191 | train acc: 99.96399688720703 | test acc: 74.2699966430664\n",
      "\n",
      "Epoch: 192\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.168 | Acc: 75.781% (97/128)\n",
      "Epoch: 192 | train acc: 99.97000122070312 | test acc: 74.31999969482422\n",
      "\n",
      "Epoch: 193\n",
      "0 391 Loss: 0.007 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.131 | Acc: 75.781% (97/128)\n",
      "Epoch: 193 | train acc: 99.97200012207031 | test acc: 74.4000015258789\n",
      "\n",
      "Epoch: 194\n",
      "0 391 Loss: 0.007 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.161 | Acc: 75.000% (96/128)\n",
      "Epoch: 194 | train acc: 99.97000122070312 | test acc: 74.27999877929688\n",
      "\n",
      "Epoch: 195\n",
      "0 391 Loss: 0.003 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.131 | Acc: 75.781% (97/128)\n",
      "Epoch: 195 | train acc: 99.97799682617188 | test acc: 74.38999938964844\n",
      "\n",
      "Epoch: 196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 391 Loss: 0.006 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.155 | Acc: 75.781% (97/128)\n",
      "Epoch: 196 | train acc: 99.96600341796875 | test acc: 74.2699966430664\n",
      "\n",
      "Epoch: 197\n",
      "0 391 Loss: 0.004 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.152 | Acc: 75.781% (97/128)\n",
      "Epoch: 197 | train acc: 99.96399688720703 | test acc: 74.25\n",
      "\n",
      "Epoch: 198\n",
      "0 391 Loss: 0.005 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.147 | Acc: 75.000% (96/128)\n",
      "Epoch: 198 | train acc: 99.96800231933594 | test acc: 74.2699966430664\n",
      "\n",
      "Epoch: 199\n",
      "0 391 Loss: 0.004 | Acc: 100.000% (128/128)\n",
      "0 79 Loss: 1.143 | Acc: 74.219% (95/128)\n",
      "Epoch: 199 | train acc: 99.96399688720703 | test acc: 74.31999969482422\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "outModelName = 'pretrain'\n",
    "if not os.path.exists(logname):\n",
    "  with open(logname, 'w') as logfile:\n",
    "      logwriter = csv.writer(logfile, delimiter=',')\n",
    "      logwriter.writerow(['epoch', 'train loss', 'train acc', 'test loss', 'test acc'])\n",
    "\n",
    "for epoch in range(start_epoch, max_epochs):\n",
    "  adjust_learning_rate(optimizer, epoch)\n",
    "  train_loss, train_acc = train(net, epoch, use_cuda=use_cuda)\n",
    "  test_loss, test_acc = test(net, epoch, outModelName, use_cuda=use_cuda)\n",
    "  with open(logname, 'a') as logfile:\n",
    "    logwriter = csv.writer(logfile, delimiter=',')\n",
    "    logwriter.writerow([epoch, train_loss, train_acc.item(), test_loss, test_acc.item()])\n",
    "  print(f'Epoch: {epoch} | train acc: {train_acc} | test acc: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Transfer learning\n",
    "### Re-use the trained model to improve training on a different data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Delete variables from the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# delete the backbone network\n",
    "delete = True\n",
    "if delete:\n",
    "  del net\n",
    "  del trainset\n",
    "  del testset\n",
    "  del trainloader\n",
    "  del testloader\n",
    "  gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "#### Target dataset\n",
    "\n",
    "We will now use CIFAR-10 as _target_ data set. Again, with small tweaks we can get any other data we are interested in.\n",
    "\n",
    "CIFAR-10 is very similar to CIFAR-100, but it contains only 10 classes instead of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing target domain data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Target domain Data\n",
    "print('==> Preparing target domain data..')\n",
    "\n",
    "# CIFAR10 normalizing\n",
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std = (0.2023, 0.1994, 0.2010)\n",
    "num_classes = 10\n",
    "lr = 0.0001\n",
    "\n",
    "# torchvision transforms\n",
    "transform_train = transforms.Compose([])\n",
    "if torchvision_transforms:\n",
    "    transform_train.transforms.append(transforms.RandomCrop(32, padding=4))\n",
    "    transform_train.transforms.append(transforms.RandomHorizontalFlip())\n",
    "\n",
    "transform_train.transforms.append(transforms.ToTensor())\n",
    "transform_train.transforms.append(transforms.Normalize(mean, std))\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./CIFAR10', train=True, download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./CIFAR10', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "#### Select a subset of the data\n",
    "\n",
    "To simulate a lower data regime, where transfer learning can be useful.\n",
    "\n",
    "Choose percentage from the trainset. Set `percent = 1.0` to use the whole train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the new trainset:  30000\n"
     ]
    }
   ],
   "source": [
    "percent = 0.6\n",
    "\n",
    "trainset = percentageSplit(trainset, percent = percent)\n",
    "print('size of the new trainset: ', len(trainset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "#### Dataloaders\n",
    "\n",
    "As before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> number of workers: 8\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "print(f'----> number of workers: {num_workers}')\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Load pre-trained model\n",
    "\n",
    "Load the checkpoint of the model previously trained on CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===> loading pretrained model from:  checkpoint/pretrain.t7\n",
      "Best Accuracy: tensor(74.5400)\n",
      "Load pretrained model with msg: <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18()\n",
    "\n",
    "checkpointPath = 'checkpoint/pretrain.t7'\n",
    "\n",
    "print(' ===> loading pretrained model from: ', checkpointPath)\n",
    "if os.path.isfile(checkpointPath):\n",
    "  state_dict = torch.load(checkpointPath)\n",
    "  best_acc = state_dict['acc']\n",
    "  print('Best Accuracy:', best_acc)\n",
    "  if \"state_dict\" in state_dict:\n",
    "      state_dict = state_dict[\"state_dict\"]\n",
    "  # remove prefixe \"module.\"\n",
    "  state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "  for k, v in model.state_dict().items():\n",
    "    if k not in list(state_dict):\n",
    "      print('key \"{}\" could not be found in provided state dict'.format(k))\n",
    "    elif state_dict[k].shape != v.shape:\n",
    "      print('key \"{}\" is of different shape in model and provided state dict'.format(k))\n",
    "      state_dict[k] = v\n",
    "  msg = model.load_state_dict(state_dict, strict=False)\n",
    "  print(\"Load pretrained model with msg: {}\".format(msg))\n",
    "else:\n",
    "  raise Exception('No pretrained weights found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Freeze model parameters\n",
    "\n",
    "In transfer learning, we usually do not re-train all the weights of the model, but only a subset of them, for instance the last layer. Here we first _freeze_ all the parameters of the model, and we will _unfreeze_ one layer below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Freeze the model parameters, you can also freeze some layers only\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Loss function, optimizer and _unfreeze_ last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "num_ftrs = model.linear.in_features\n",
    "model.linear = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.linear.parameters(),\n",
    "    lr=lr,\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "#### Check number of parameters\n",
    "\n",
    "We can calculate the number of total parameters and the number of trainable parameters, that is those that will be updated during training. Since we have freezed most of the parameters, the number of training parameters should be much smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 11173962 Trainable parameters:  5130\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('Total Parameters:', total_params, 'Trainable parameters: ', trainable_total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "### Train the target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "0 235 Loss: 2.305 | Acc: 12.500% (16/128)\n",
      "0 79 Loss: 0.675 | Acc: 79.688% (102/128)\n",
      "Saving..\n",
      "Epoch: 0 | train acc: 71.99333190917969 | test acc: 75.87999725341797\n",
      "\n",
      "Epoch: 1\n",
      "0 235 Loss: 0.617 | Acc: 78.125% (100/128)\n",
      "0 79 Loss: 0.684 | Acc: 72.656% (93/128)\n",
      "Epoch: 1 | train acc: 75.43333435058594 | test acc: 73.66000366210938\n",
      "\n",
      "Epoch: 2\n",
      "0 235 Loss: 0.541 | Acc: 80.469% (103/128)\n",
      "0 79 Loss: 0.602 | Acc: 77.344% (99/128)\n",
      "Epoch: 2 | train acc: 76.34333038330078 | test acc: 75.56999969482422\n",
      "\n",
      "Epoch: 3\n",
      "0 235 Loss: 0.581 | Acc: 76.562% (98/128)\n",
      "0 79 Loss: 0.574 | Acc: 80.469% (103/128)\n",
      "Saving..\n",
      "Epoch: 3 | train acc: 76.93000030517578 | test acc: 77.08999633789062\n",
      "\n",
      "Epoch: 4\n",
      "0 235 Loss: 0.461 | Acc: 84.375% (108/128)\n",
      "0 79 Loss: 0.602 | Acc: 78.906% (101/128)\n",
      "Epoch: 4 | train acc: 77.52999877929688 | test acc: 75.9800033569336\n",
      "\n",
      "Epoch: 5\n",
      "0 235 Loss: 0.687 | Acc: 76.562% (98/128)\n",
      "0 79 Loss: 0.550 | Acc: 80.469% (103/128)\n",
      "Saving..\n",
      "Epoch: 5 | train acc: 77.17333221435547 | test acc: 78.16000366210938\n",
      "\n",
      "Epoch: 6\n",
      "0 235 Loss: 0.485 | Acc: 82.812% (106/128)\n",
      "0 79 Loss: 0.553 | Acc: 78.906% (101/128)\n",
      "Epoch: 6 | train acc: 77.80000305175781 | test acc: 76.7300033569336\n",
      "\n",
      "Epoch: 7\n",
      "0 235 Loss: 0.490 | Acc: 78.906% (101/128)\n",
      "0 79 Loss: 0.540 | Acc: 78.125% (100/128)\n",
      "Epoch: 7 | train acc: 77.61666870117188 | test acc: 76.66000366210938\n",
      "\n",
      "Epoch: 8\n",
      "0 235 Loss: 0.527 | Acc: 82.812% (106/128)\n",
      "0 79 Loss: 0.560 | Acc: 79.688% (102/128)\n",
      "Epoch: 8 | train acc: 77.73666381835938 | test acc: 77.27999877929688\n",
      "\n",
      "Epoch: 9\n",
      "0 235 Loss: 0.763 | Acc: 76.562% (98/128)\n",
      "0 79 Loss: 0.643 | Acc: 77.344% (99/128)\n",
      "Epoch: 9 | train acc: 77.61333465576172 | test acc: 76.13999938964844\n"
     ]
    }
   ],
   "source": [
    "outModelName = 'finetuned'\n",
    "logname = result_folder + model.__class__.__name__ + f'_{outModelName}.csv'\n",
    "\n",
    "if not os.path.exists(logname):\n",
    "  with open(logname, 'w') as logfile:\n",
    "    logwriter = csv.writer(logfile, delimiter=',')\n",
    "    logwriter.writerow(['epoch', 'train loss', 'train acc', 'test loss', 'test acc'])\n",
    "\n",
    "for epoch in range(start_epoch, max_epochs_target):\n",
    "  adjust_learning_rate(optimizer, epoch)\n",
    "  train_loss, train_acc = train(model, epoch, use_cuda=use_cuda)\n",
    "  test_loss, test_acc = test(model, epoch, outModelName, use_cuda=use_cuda)\n",
    "  with open(logname, 'a') as logfile:\n",
    "    logwriter = csv.writer(logfile, delimiter=',')\n",
    "    logwriter.writerow([epoch, train_loss, train_acc.item(), test_loss, test_acc.item()])\n",
    "  print(f'Epoch: {epoch} | train acc: {train_acc} | test acc: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train loss</th>\n",
       "      <th>train acc</th>\n",
       "      <th>test loss</th>\n",
       "      <th>test acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.833534</td>\n",
       "      <td>70.783333</td>\n",
       "      <td>0.705926</td>\n",
       "      <td>74.870003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.702357</td>\n",
       "      <td>75.089996</td>\n",
       "      <td>0.673588</td>\n",
       "      <td>76.230003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.674137</td>\n",
       "      <td>76.176666</td>\n",
       "      <td>0.682912</td>\n",
       "      <td>75.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.655623</td>\n",
       "      <td>76.900002</td>\n",
       "      <td>0.664979</td>\n",
       "      <td>77.059998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.645413</td>\n",
       "      <td>77.199997</td>\n",
       "      <td>0.645370</td>\n",
       "      <td>77.300003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train loss  train acc  test loss   test acc\n",
       "0      0    0.833534  70.783333   0.705926  74.870003\n",
       "1      1    0.702357  75.089996   0.673588  76.230003\n",
       "2      2    0.674137  76.176666   0.682912  75.820000\n",
       "3      3    0.655623  76.900002   0.664979  77.059998\n",
       "4      4    0.645413  77.199997   0.645370  77.300003"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# title plot results\n",
    "results = pd.read_csv(f'results/ResNet_{outModelName}.csv', sep =',')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy over 10 epochs: 76.0\n",
      "best accuraccy over 10 epochs: 78.16000366210938\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = results['train acc'].values\n",
    "test_accuracy = results['test acc'].values\n",
    "\n",
    "print(f'Average Accuracy over {max_epochs_target} epochs:', sum(test_accuracy)//len(test_accuracy))\n",
    "print(f'best accuraccy over {max_epochs_target} epochs:', max(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {}
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figureName = 'figure' # change figure name\n",
    "\n",
    "plt.plot(results['epoch'].values, train_accuracy, label='train')\n",
    "plt.plot(results['epoch'].values, test_accuracy, label='test')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(f'Train/Test Accuracy curve for {max_epochs} epochs')\n",
    "plt.savefig(f'results/{figureName}.png')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "transfer_learning",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
